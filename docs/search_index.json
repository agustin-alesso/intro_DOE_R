[
["index.html", "Introducción al diseño y análisis estadístico de experimentos usando R Introducción", " Introducción al diseño y análisis estadístico de experimentos usando R Agustín Alesso Introducción Este pequeño libro (en construcción) tiene como objetivo servir como material introductorio al diseño y análisis estadístico de experimentos utilizando el software R como soporte para cálculos. ¿Qué cubre? Introducción a R/Rstudio Repaso de estadística básica Principios de diseño Diseños más empleados Al final del libro se espera que el lector: Reconozca la importancia del enfoque estadístico para el diseño de experimentos. Tenga un sólido entendimiento de los principales métodos utilizados para el análisis de datos provenientes de experimentos diseñados. Sepa interpretar los resultados de los análisis estadísticos en contexto de las ciencias biológicas y agrícolas. Desarrolle destrezas mínimas para utilizar el paquete estadístico R y el entorno de trabajo RStudio. "],
["empezando-con-r-y-rstudio.html", "Capítulo 1 Empezando con R y RStudio 1.1 ¿Qué es R y RStudio? 1.2 ¿Cómo instalar R y RStudio? 1.3 Primera sesión", " Capítulo 1 Empezando con R y RStudio 1.1 ¿Qué es R y RStudio? R es un lenguaje y entorno para el procesamiento, visualización y análisis estadístico de datos. Ha sido creado en 1993 por R. Gentleman y R. Ihaka, ambos científicos del Departamento de Estadística de la Universidad de Auckland (Nueva Zelanda). Actualmente su desarrollo y mantenimiento está a cargo del R Core Team. El sitio oficial del proyecto es www.r-project.org Figure 1.1: Página oficial de R Project Hoy en día, R es la lingua franca del procesamiento y análisis de datos, tanto en el ámbito académico como comercial dado que es gratiuto, multiplataforma, de código abierto (open source, liberado con licencia GNU/GPL). Esto y el ecosistema de paquetes contribuidos por la comunidad de usuarios lo convierte en un software muy potente ya que expresa el estado del arte de los métodos estadísticos. Al igual que su antecesor S, la flexibilidad y potencia de R se basa en su interfaz de comandos (CLI, del inglés command line interface ) que permite la ejecución de comandos de manera interactiva (en consola) o estructurada mediante scritps. Figure 1.2: Consola o terminal de Windows, Mac OS X y Linux corriendo la última versión estable de R Figure 1.2: Consola o terminal de Windows, Mac OS X y Linux corriendo la última versión estable de R Existen algunos desarrollos de interfases gráficas (GUIs, del inglés graphical user interface), e.g. RCommander, Deducer, etc., que ofrecen la posibilidad de, mediante menues y botones dedicados, ejecutar algunos análisis relativamente simples minimizando la necesidad de escribir código. Figure 1.3: Interfase de R Commander Los entornos de desarrollo integrados (IDE por sus siglas en inglés integrated development environments) ofrecen un enfoque intermedio ya que los menúes o funciones asistentes facilitan algunas tareas generales (abrir archivos, carga de datos, exportar gráficos y resultados, etc.) pero dejan la codificación y ejecución del análisis estadístico en manos del usuario. Entre estas alternativas se destaca RStudio ( www.rstudio.com ) el cual también es de código abierto (licencia GNU/GPL), multiplataforma y ofrece una versión gratuita. Figure 1.4: Interfase de RStudio 1.2 ¿Cómo instalar R y RStudio? R y RStudio se instalan por separado. R puede funcionar sin RStudio, en cambio éste necesita que al menos una versión de R esté instalada en el sistema. Ambos softwares son multiplataforma y pueden ser ejecutados en sistemas operativos Windows, OS X y Linux. En la página https://cloud.r-project.org/ hay instrucciones específicas para cada plataforma. A continuación se describe el procedimiento para instalar R y RStudio bajo Windows. 1.2.1 Instalación de R Descargar el archivo instalador correspondiente a la última versión estable de R desde el CRAN1 (del inglés, Comprenhensive R Archive Network) visitando el siguiente link. Figure 1.5: Página de descaga de R Ejecutar el archivo descargado2 y seguir el asistente de instalación con todas las opciones por defecto. Si la instalación ha sido exitosa en el menú Inicio podrá encontrarse la carpeta R que contendrá dos accesos directos a la interfase de usuario mínima que viene con la versión de R para Windows. Figure 1.6: R GUI para Windows 1.2.2 Instalación de RStudio Ir al sitio web de descarga de RStudio https://www.rstudio.com/products/rstudio/download/ Figure 1.7: Página principal de RStudio Descargar el archivo de instalación correspondiente a nuestra plataforma o sistema operativo. Figure 1.8: Página principal de RStudio Ejecutar el archivo .exe3 y seguir el asistente de instalación con todas las opciones por defecto. Si la instalación ha sido exitosa en el menú Inicio dentro de la carpeta RStudio se encontrará el acceso directo a RStudio el cual, mediante el menu contextual (botón derecho del ratón) puede enviarse al Escritorio como acceso directo o bien anclar al menu de Inicio o barra de acceso rápido. Ahora sí, ya tenemos listo R y RStudio para empezar a trabajar!! 1.3 Primera sesión El entorno de trabajo de RStudio se divide en cuatro paneles. El contenido y disposición de los paneles puede personalizarse mediante el menu View &gt; Panes. A continuación la descripción de los paneles por defecto. Figure 1.9: Interfase principal de RStudio Editor. Es donde se editan los scripts que son archivos con los comandos para ejecutar en R. Por defecto este panel no aparece a menos que se cree un nuevo script o se abra uno previamente guardado. Es básicamente un editor de texto plano como el block de notas, aunque tiene algunas funcionalidades importantes: Resaltado sintaxis: mediante colores resalta las funciones, variables, comandos o palabras claves del lenguaje R Sangrado automático: agrega espacios en blanco para mantener la sangría de los bloques de código. Completado automático: muestra sugerencias para completar el comando o argumentos usando la tecla TAB. Console (consola). Es donde reside R propiamente dicho. Allí se ejecutan los comandos y se obtienen las salidas de R. El símbolo es &gt; indica que R está disponible para recibir un comando que puede ser tipeado directamente, o bien enviado desde el editor (1) de scripts usando la combinación CTRL + ENTER o CTRL + R. Environmnet/History/Connections. En la primera pestaña se visualizan los objetos (variables, funciones o datos cargados) que están disponibles en el entorno de R, i.e. en la memoria. En la segunda se puede ver el historial de comandos ingresados o enviados a la consola. La tercera pestaña visualiza las conexiones establecidas con diferentes base de datos. Files/Plots/Packages/Help/Viewer. Allí se puede manejar los archivos del directorio de trabajo, visualizar los gráficos generados en R con posibilidad de exportarlos en varios formatos, administrar los paquetes o complementos, buscar o explorar el manual de ayuda y previsualizar archivos HTML. 1.3.1 La consola La línea de comandos o consola es el modo interactivo mediante el cual podemos ejecutar comandos directamente en el intérprete de R. El símbolo o prompt &gt; indica que R está disponible esperando una orden. Si la orden no está completa el símbolo se transforma en +. Por ejemplo: 2 + 2 2 + 2 ## [1] 4 Otro ejemplo: el promedio de los números 1, 3 y 4 (1 + 3 + 4) / 3 ## [1] 2.666667 1.3.2 El script El editor de scripts (panel 1) es un editor de texto plano que está conectado con la consola (panel 2) y, gracias a algunas funcionalidades (resaltado de sinbtaxis, numeración de lineas, plegado de código, autocompletado, etc) facilitan la edición de código para programar los comandos a ejecutar por R. Para crear un nuevo script se puede usar uno de los siguientes métodos: Ir a al menu File &gt; New File &gt; R Script Usar el atajo de teclado CTRL + SHIFT + N Clickear en el primer ícono de la barra de menu Figure 1.10: Barra de herramientas de RStudio Una vez abierto el script en blanco, se pueden empezar a escribir los comandos de R, por ejemplo: # Calcular el promedio de estos números (1 + 3 + 4) / 3 &quot;Hola Mundo!&quot; # Clásico mensaje &quot;Hola mundo!&quot; Para ejecutar estos comandos en la consola hay que posicionarse en la línea o seleccionar las líneas que se quieren ejecutar y luego algunas de las siguientes opciones: Ir al menu Code &gt; Run Selected Line(s) Usar el atajo de teclado CTRL + ENTER o CTRL + R Usar el ícono Run de la barra de herramientas de la pestaña del script Figure 1.11: Barra de herramientas del panel Editor El simbolo # indica que lo que sigue es un comentario y por lo tanto R lo ignora cuando es enviado a la consola. Los comentarios pueden ir solos en una línea separada o bien dentro de una línea que tenga algún comando. Si bien no son necesarios para correr el código, los comentarios son muy útiles para estructurar el script y hacer anotaciones para que otros, o nosotros en un futuro, entiendan lo que hace esa parte del script. Para guardar el script: Ir al menu File &gt; Save o usar el atajo de teclado CTRL + S o bien el ícono con el diskette de la barra de herramientas global o de la pestaña del script activo. Elegir la carpeta destino y el nombre de archivo. Automáticamente se agregará la extensión .R que corresponde a los scripts. 1.3.3 Proyecto R trabaja con un directorio de trabajo o working directory que es la dirección o path que figura en el titulo del panel Console. Por defecto es el directorio base del usuario que depende de cada plataforma. En linux es el /home/usuario en cambio en Windows es C:/Users/usuario/Documents. A menos que se especifique lo contrario, se asume que los archivos de entrada o salida se ubican en dicha carpeta. Esto se puede modificar en cualquier momento con la función setwd(). RStudio extiende esta característica a través de los proyectos o projects. Cada proyecto es una carpeta o folder que contienen un archivo .RProj con algunas configuraciones específicas. Al abrirlo en RStudio, automáticamente se cambia el directorio de trabajo a esta carpeta. Esto permite organizar los archivos de datos, las salidas, los scripts, etc., dentro de un directorio de trabajo (working directory) y volver a ellos de manera más rápida, eficiente, y portable. Para crear un proyecto: Ir a File &gt; New project... o bien el ícono Create project de la barra de herramientas. Seleccionar New Directory y en Project type seleccionar New project. Una vez en el cuadro de diálogo Create new project ingresar el nombre del proyecto (e.g. DOE) en Directory name que será a su vez el nombre de la carpeta que RStudio va a crear por nosotros. Luego en Create project as a subdirectory of indicar donde queremos que Rstudio cree la carpeta. Si todo sale bien, se crea la carpeta con el nombre que indicamos y dentro de ésta un archivo con extensión .Rproj 1.3.4 Ayuda!!! Por último, y no menos importante, R y RStudio cuentan con un completo sistema de ayuda. Desde la consola se puede acceder usando la función ? seguida del nombre de la función o bien help(&quot;nombre&quot;) # Pedir ayuda de la función mean ?mean help(mean) No obstante, una de las ventajas de RStudio es que dispone de un panel (Panel #4) dedicado a visualizar las páginas de ayuda. Allí se puede navegar por las páginas utilizando los links, realizar búsquedas, etc. Leer la documentación nunca viene mal y generalmente ahorra dolores de cabeza. CRAN se compone de un conjunto de servidores espejo distribuidos alrededor del mundo que tienen copias de R y sus paquetes. No es necesario escojer el espejo más cercano ya que el espejo nube (https://cloud.r-project.org) automáticamente determina de que servidor conviene realizar la descarga.↩ Al momento de escribir estas instrucciones la última versión estable de R era la 3.5.1 “Feather Spray”, por lo tanto el link apuntará al archivo R-3.5.1-win.exe.↩ Al momento de escribir estas instrucciones la última versión estable de RStudio era RStudio-1.1.453.exe.↩ "],
<<<<<<< HEAD
["aspectos-basicos-del-lenguaje-r.html", "Capítulo 2 Aspectos básicos del lenguaje R 2.1 Operadores matemáticos 2.2 Operadores lógicos 2.3 Variables y objetos 2.4 Funciones y argumentos 2.5 Vectores 2.6 Tipos de datos 2.7 Estructura de datos", " Capítulo 2 Aspectos básicos del lenguaje R En el capítulo anterior se introdujo la interfase básica de R (la consola) y la edición de secuencias de comandos mediante el uso de scripts. También se mostró la creación y uso de proyectos en RStudio. En este capítulo se abordarán los conceptos básicos del lenguaje R tales como operadores para representar operaciones matemáticas (suma, resta, etc), tipos de variables y objetos para representar los datos, y características generales de las funciones o comandos. 2.1 Operadores matemáticos En R las operaciones matemáticas básicas: suma (+), resta (-), división (/), producto (*) y potencia (^) se realizan usando los símbolos convencionales: Por ejemplo, \\(1 + \\left( 3 \\times 4 + \\dfrac{5 -2}{3} \\right)^2\\) en R es: 1 + (3 * 4 + (5 - 2)/3)^2 ## [1] 170 2.2 Operadores lógicos R permite evaluar expresiones lógicas: igual (==), distinto (!=), mayor que (&gt;), menor que (&lt;), mayor o igual que (&gt;=), menor o igual que (&lt;=). El resultado es TRUE (verdadero) o FALSE (falso) # 3 es igual a 4? 3 == 4 ## [1] FALSE # 5 es mayor o igual 3? 5 &gt;= 3 ## [1] TRUE # 2 es distinto que 2.5 2 != 2.5 ## [1] TRUE También se pueden combinar con los operadores intersección (&amp;), unión (|) y negación (!) # Devuelve FALSE ya que las dos condiciones no se cumplen a la vez 4 == 4 &amp; 5 == 6 ## [1] FALSE # Devuelve TRUE ya que una de la dos condiciones se cumple 4 == 4 | 5 == 6 ## [1] TRUE O con operaciones matemáticas… 4 * 2 == 8 ## [1] TRUE En este caso primero evalúa 4 * 2 y luego compara el resultado con 8 2.3 Variables y objetos En R practicamente todo puede almacenarse en un objeto, es decir, un espacio de la memoria asignado a almacenar información: una cifra, un conjunto de números, el resultado de un análisis, etc. También se denomina variables ya que su contenido puede cambiar. Con el simbolo &lt;- o bien = se pueden crear objetos o variables asignándoles información (números, letras, resultados de operaciones, etc) y para luego recuperarla y utilizarla en otros cálculos. # Crea la variable x y le asgina el valor 2 x &lt;- 2 x ## [1] 2 # Operación con variables 2 * x ## [1] 4 # Usar variables para definir nuevas variables y &lt;- 2 * x +1 y ## [1] 5 Aclaración: los nombres de las variables no deben empezar con números ni contener espacios. No pueden usarse operadores en los nombres pero puede usarse . o _. # Mal 2x &lt;- 3 mi variable &lt;- 3 # Bien x_2 &lt;- 3 x.2 &lt;- 3 x2 &lt;- 3 También R es sensibles a mayúsculas # Definir &#39;A&#39; y &#39;a&#39; A &lt;- 3 a &lt;- 5 # Verificar si &#39;A&#39; y &#39;a&#39; son lo mismo A == a ## [1] FALSE 2.4 Funciones y argumentos Las funciones dentro de R tienen la siguiente forma: nombre_funcion(arg1, arg2, ...), donde arg son los argumentos que toma cada función. Algunos argumentos toman valores por defecto otros hay que declararlos. Por ejemplo la función mean() tiene los argumentos: x para indicar el vector numérico sobre el cual queremos calcular el promedio trim para indicar la proporción de valores extremos excluir del cálculo (media truncada) na.rm para indicar si queremos o no excluir los valores NA. # Media truncada de 100 valores aleatorios y &lt;- runif(100) # Indicando los argumentos mean(x = y, trim = 0.1) ## [1] 0.5018551 # Sin indicar los argumentos mean(y, 0.1) ## [1] 0.5018551 En este último caso, el orden de los argumentos es clave ya que R asigna los valores en función de la posición 2.5 Vectores Son los objetos más simples a partir de los cuales se construyen otros tipos de objetos. Se crean utilizando la función c() para “combinar” datos del mismo tipo. x &lt;- c(13, 45, 67, 45) x ## [1] 13 45 67 45 Pueden contener un solo tipo de datos a la vez: numérico, texto, lógico. En el caso de mezcla de datos, R los va a coaccionar al tipo de datos más simple. Por ejemplo: si queremos crear un vector con 3 valores: lógico, numerico y texto, R va a asumir que todos los elementos son de tipo texto x &lt;- c(TRUE, 34, &quot;texto&quot;) x ## [1] &quot;TRUE&quot; &quot;34&quot; &quot;texto&quot; Los vectores están indexados y se puede acceder a sus elementos usando el operador [ ] e indicando el número de orden. Por ejemplo: # 3er elemento del vector x x[3] ## [1] &quot;texto&quot; 2.6 Tipos de datos 2.6.1 Numéricos (numeric) Números racionales (enteros o con coma). Los números enteros se tratan como numeric a menos que se los convierta con as.integer(). x &lt;- c(3, 4, 5) class(x) ## [1] &quot;numeric&quot; # Convertir a enteros y &lt;- as.integer(x) class(y) ## [1] &quot;integer&quot; Los datos numéricos permiten todas las operaciones algebráicas # La media aritmética de x mean(x) ## [1] 4 2.6.2 Texto (character) Cadenas de texto o número delimitadas por comillas (simples o dobles). x &lt;- c(&quot;hola&quot;, &#39;3&#39;, &quot;estadística1&quot;) class(x) ## [1] &quot;character&quot; Lógicamente, no se pueden realizar operaciones numéricas. Se pueden 2.6.3 Lógicos (logic) Condición verdadero (TRUE o T) o falso (FALSE o F) logico &lt;- c(T, F, T, TRUE, FALSE, F) logico ## [1] TRUE FALSE TRUE TRUE FALSE FALSE Ejemplo: ¿que números son mayores a 30? x &lt;- c(23, 43, 21, 34, 56, 3, 23, 3) x &gt; 30 ## [1] FALSE TRUE FALSE TRUE TRUE FALSE FALSE FALSE 2.6.4 Otros Los valores faltantes se simbolizan en R con NA. Indican que debería haber in valor pero que está faltando x &lt;- c(1, 2, 3, NA, 4) is.na(x) ## [1] FALSE FALSE FALSE TRUE FALSE A diferencia del NA, un valor de tipo NULL indica que no hay información y que tampoco se esperaba que la haya. x &lt;- c(1, 2, 3, NULL, 4) x ## [1] 1 2 3 4 Algunas operaciones matemáticas devuelven valores NaN cuando no están definidas, por ejemplo: 0/0 ## [1] NaN O bien valores infinitos: 1/0 ## [1] Inf 2.7 Estructura de datos 2.7.1 Matriz (matrix) Colección de vectores de igual longitud y mismo tipo de datos. Se crea con la función matrix(), o combinando filas o columnas de igual longitud con rbind() o cbind(). M &lt;- matrix(c(1, 2, 3, 4, 5, 6), ncol = 2) M ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 Se puede indexar usando [n, p] donde n es el numero de fila y p numero de columna. # Elemento m12 M[1,2] ## [1] 4 # Toda la columna 2 M[, 2] ## [1] 4 5 6 2.7.2 Listas (list) Generalización de los vectores ya que los elementos pueden ser de igual o diferente tipo de datos l &lt;- list(23, &quot;hola&quot;, TRUE) l ## [[1]] ## [1] 23 ## ## [[2]] ## [1] &quot;hola&quot; ## ## [[3]] ## [1] TRUE Se pueden indexar usando [[ ]] # El segundo elemento de l l[[2]] ## [1] &quot;hola&quot; Cada elemento a su vez puede ser cualquier objeto de los vistos anteriormente. 2.7.3 Hoja de datos (data.frame) Similares a las matrices pero cada columna puede ser de un tipo de dato diferente. Útil para guardar datos donde cada fila es un caso y cada columna una variable. trigo &lt;- data.frame( lote = 1:5, rendimiento = c(34, 36, 40, 28, 31), variedad = c(&#39;Escorpion&#39;, &#39;Escorpion&#39;, &#39;Yarara&#39;, &#39;Baguette 11&#39;, &#39;Tijetera&#39;) ) trigo ## lote rendimiento variedad ## 1 1 34 Escorpion ## 2 2 36 Escorpion ## 3 3 40 Yarara ## 4 4 28 Baguette 11 ## 5 5 31 Tijetera Se puede acceder a cada columna (vectores) con $ # Variedades trigo$variedad ## [1] Escorpion Escorpion Yarara Baguette 11 Tijetera ## Levels: Baguette 11 Escorpion Tijetera Yarara O indexar con indexar con [ ] # El bombre de la varidedad de la fila 2 trigo[2, 3] ## [1] Escorpion ## Levels: Baguette 11 Escorpion Tijetera Yarara # Todos los datos de la fila 2 trigo[2, ] ## lote rendimiento variedad ## 2 2 36 Escorpion # Lotes con rendimiento mayor a 35 qq/ha trigo[trigo$rendimiento &gt; 35, ] ## lote rendimiento variedad ## 2 2 36 Escorpion ## 3 3 40 Yarara 2.7.4 Factores (factor y ordered) Si los elementos de vector de tipo texto (character) representan niveles nominales (categorías), el objeto puede convertirse a factor de modo tal que los valores son reemplazados por un número que se asocia a los niveles del factor (ordenados alfabeticamente, a menos que se indique otra cosa). x &lt;- c(&#39;bajo&#39;, &#39;medio&#39;, &#39;alto&#39;, &#39;alto&#39;, &#39;bajo&#39;, &#39;bajo&#39;) x ## [1] &quot;bajo&quot; &quot;medio&quot; &quot;alto&quot; &quot;alto&quot; &quot;bajo&quot; &quot;bajo&quot; # factor nominal y &lt;- factor(x) y ## [1] bajo medio alto alto bajo bajo ## Levels: alto bajo medio as.numeric(y) ## [1] 2 3 1 1 2 2 En el ejemplo anterior, los valores eran bajo, medio y alto. Mediante la función estos valores pasaron al atributo levels y los datos fueron reemplazados por los identificadores 2, 3, y 1. Cuando los niveles tienen una jerarquía u orden, se puede especificar este tipo de relación mediante as.ordered() que convierte el factor en ordered agregando la relación entre los niveles # Factor ordinal z &lt;- factor(x, levels = c(&#39;bajo&#39;, &#39;medio&#39;, &#39;alto&#39;)) z &lt;- as.ordered(z) z ## [1] bajo medio alto alto bajo bajo ## Levels: bajo &lt; medio &lt; alto Los factores como cualquier vectore tambien se indexan con [ ]. "],
["introduccion-a-dplyr.html", "Capítulo 3 Introducción a dplyr 3.1 ¿Qué es dplyr? 3.2 ¿Cómo conseguir dplyr? 3.3 Verbos importantes de dplyr para recordar 3.4 dplyr en acción", " Capítulo 3 Introducción a dplyr En este capítulo y el siguiente se introducirán dos paquetes de R que están siendo ampliamente utilizados por la comunidad: dplyr y ggplot2. 3.1 ¿Qué es dplyr? dplyr es un paquete de R muy potente para la exploración, transformación y resumen de datos en formato de tabla con filas (observaciones) y columnas (variables). Es un componente de un conjunto de packages llamado tidyverse desarrollados por Hadley Wickham El paquete contiene un conjunto de funciones (o verbos) que realizan operaciones comunes para el manejo de datos tales como: filtrar filas, seleccionar columnas, re-ordenar filas, agregar o transformar columnas, resumir datos. También permite agrupar los datos facilitando la estrategia split-apply-combine, es decir, dividir (split) los datos según una variable de grupo, aplicar (apply) alguna transformación o resumen y combinar (combine) las partes para presentar los resultados. Si bien R base tiene funciones que realizan las mismas tareas (split(), subset(), apply(), sapply(), lapply(), tapply() and aggregate()), el paquete dplyr brinda una interface más consistente que permite trabajar de manera más facil con data.frame (tabla de datos) más que con vectores. 3.2 ¿Cómo conseguir dplyr? Para instalar por primera vez en la computadora: # Solo install.packages(&quot;dplyr&quot;) # O junto con la familia tidyverse install.packages(&quot;tidyverse&quot;) Lo anterior se debe realizar por única vez si el paquete no está previamente instalado en la máquina. Para usar las funciones en una sesion de trabajo hay que cargarlo con library(): # Solo library(&quot;dplyr&quot;) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union # O junto con la familia tidyverse library(&quot;tidyverse&quot;) ## ── Attaching packages ───────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ readr 1.1.1 ## ✔ tibble 1.4.2 ✔ purrr 0.2.5 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ ggplot2 3.0.0 ✔ forcats 0.3.0 ## ── Conflicts ──────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() R va a avisarnos en la consola que esta enmascarando (reemplazando) algunas funciones que ya estaban en el entorno, o bien el paquete nos devuelve algun mensaje. A menos que diga Error ..., eso está bien. 3.3 Verbos importantes de dplyr para recordar Toda la estrategia de trabajo con datos de dplyr se basa en 6 verbos: verbo descripción select() selecciona columnas (variables) filter() filtra o selecciona las filas (observaciones) arrange() re-ordena las filas mutate() crea nuevas columnas o modifica las preexistentes summarise() resumen los valores de una variable group_by() permite aplicar los verbos anteriores en subgrupos (split-apply-combine) sample_n() para tomar muestras aleatorias con o sin reposición En la mayoría de los casos la sintaxis es: function(que_datos, que_hacer_con_los_datos) En que_datos hay que poner el nombre del set de datos o data.frame (a menos que se use el operador %&gt;% para encadenar, mas adelante) y en que_hacer_con_los_datos indicar que operación, condicion, transformacion, etc aplicar a las filas y columnas. 3.4 dplyr en acción Para ilustrar el uso del paquete vamos a usar los datos contenidos en el archivo pesada_terneros.xlsx. # Cargar los datos con readxl library(readxl) terneros &lt;- read_excel(&quot;./data/pesada_terneros.xlsx&quot;) 3.4.1 Seleccionando variables Una tareas básicas cuando se exploran datos es la selección de columnas de interés (variables). Esto se lleva a cabo con select(). Para seleccionar las columnas Procedencia, IDV y Peso: # Sin asignar select(terneros, Procedencia, IDV, Peso) ## # A tibble: 1,598 x 3 ## Procedencia IDV Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita NR047A202 204 ## 2 La Rosita GN685B267 186 ## 3 La Rosita AI101A751 182 ## 4 La Rosita TM603C877 186 ## 5 La Rosita TM420B797 186 ## 6 La Rosita LH837F500 208 ## 7 La Rosita NR047A217 170 ## 8 La Rosita LH837F508 188 ## 9 La Rosita GN685B256 172 ## 10 La Rosita QW110A058 172 ## # ... with 1,588 more rows # Creando un nuevo set de datos mis_columnas &lt;- select(terneros, Procedencia, IDV, Peso) Por defecto, si no se asigna a un nuevo objeto, el resultado de la operación se imprime en la consola con la función print() la cual por defecto muestra las 10 primeras observaciones y la cantidad de columnas que entran en la pantalla. Aquellas columnas que no entran son indicadas al pie. Si quiero ver más registros se puede usar el argumento n = de print() print(mis_columnas, n = 15) ## # A tibble: 1,598 x 3 ## Procedencia IDV Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita NR047A202 204 ## 2 La Rosita GN685B267 186 ## 3 La Rosita AI101A751 182 ## 4 La Rosita TM603C877 186 ## 5 La Rosita TM420B797 186 ## 6 La Rosita LH837F500 208 ## 7 La Rosita NR047A217 170 ## 8 La Rosita LH837F508 188 ## 9 La Rosita GN685B256 172 ## 10 La Rosita QW110A058 172 ## 11 La Rosita LH837F497 188 ## 12 La Rosita TM420B803 180 ## 13 La Rosita LH837F514 198 ## 14 La Rosita II641B940 200 ## 15 La Rosita IY735C 242 ## # ... with 1,583 more rows Con n = &quot;all&quot; se imprimen todas (no se muestra por razones obvias) El orden en que aparecen las variables en el resultado es el orden que se utilizó al seleccionarlas. # El orden altera el producto select(terneros, Procedencia, IDV, Peso) ## # A tibble: 1,598 x 3 ## Procedencia IDV Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita NR047A202 204 ## 2 La Rosita GN685B267 186 ## 3 La Rosita AI101A751 182 ## 4 La Rosita TM603C877 186 ## 5 La Rosita TM420B797 186 ## 6 La Rosita LH837F500 208 ## 7 La Rosita NR047A217 170 ## 8 La Rosita LH837F508 188 ## 9 La Rosita GN685B256 172 ## 10 La Rosita QW110A058 172 ## # ... with 1,588 more rows También se puede usar los comnados starts_with(), ends_with(), contains(), etc (ver ?select_helpers) para más opciones). Para elegir varias columnas que tienen un patron sin tener que tipear todos los nombres. # Selecciona columnas que empiezan con P select(terneros, starts_with(&quot;P&quot;)) ## # A tibble: 1,598 x 2 ## Procedencia Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita 204 ## 2 La Rosita 186 ## 3 La Rosita 182 ## 4 La Rosita 186 ## 5 La Rosita 186 ## 6 La Rosita 208 ## 7 La Rosita 170 ## 8 La Rosita 188 ## 9 La Rosita 172 ## 10 La Rosita 172 ## # ... with 1,588 more rows Para omitir algunas columnas en la seleccion se puede usar el - antes del nombre. # Selecciona columnas que empiezan con P select(terneros, -IDV, -starts_with(&quot;P&quot;)) ## # A tibble: 1,598 x 1 ## Fecha ## &lt;dttm&gt; ## 1 2017-04-06 00:00:00 ## 2 2017-04-06 00:00:00 ## 3 2017-04-06 00:00:00 ## 4 2017-04-06 00:00:00 ## 5 2017-04-06 00:00:00 ## 6 2017-04-06 00:00:00 ## 7 2017-04-06 00:00:00 ## 8 2017-04-06 00:00:00 ## 9 2017-04-06 00:00:00 ## 10 2017-04-06 00:00:00 ## # ... with 1,588 more rows 3.4.2 Seleccionando observaciones Otra tarea muy frecuente es seleccionar casos o observaciones que cumplan con alguna condición. Esto se lleva a cabo con filter(). Se pueden usar los operadores booleanos ==, &gt;, &lt;, &gt;=, &lt;=, !=, %in%) para crear pruebas o condiciones lógicas. Para seleccionar los terneros de Los Corralitos: # Sin asignar filter(terneros, Procedencia == &#39;Los Corralitos&#39;) ## # A tibble: 575 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 PO150A167 Los Corralitos 2017-04-10 00:00:00 224 ## 2 PO150A168 Los Corralitos 2017-04-10 00:00:00 234 ## 3 PO150A169 Los Corralitos 2017-04-10 00:00:00 204 ## 4 PO150A460 Los Corralitos 2017-04-10 00:00:00 196 ## 5 PO150A673 Los Corralitos 2017-04-10 00:00:00 246 ## 6 PO150A461 Los Corralitos 2017-04-10 00:00:00 196 ## 7 PO150A462 Los Corralitos 2017-04-10 00:00:00 238 ## 8 PO150A463 Los Corralitos 2017-04-10 00:00:00 210 ## 9 PO150A433 Los Corralitos 2017-04-10 00:00:00 174 ## 10 PO150A434 Los Corralitos 2017-04-10 00:00:00 222 ## # ... with 565 more rows # Creando un nuevo set de datos corralitos &lt;- filter(terneros, Procedencia == &#39;Los Corralitos&#39;) La seleccion se puede hacer por más de una condicion. Por ejemplo, seleccionar los de Los Corralitos que pesen más de 200 kg: filter(terneros, Procedencia == &#39;Los Corralitos&#39;, Peso &gt; 200) ## # A tibble: 260 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 PO150A167 Los Corralitos 2017-04-10 00:00:00 224 ## 2 PO150A168 Los Corralitos 2017-04-10 00:00:00 234 ## 3 PO150A169 Los Corralitos 2017-04-10 00:00:00 204 ## 4 PO150A673 Los Corralitos 2017-04-10 00:00:00 246 ## 5 PO150A462 Los Corralitos 2017-04-10 00:00:00 238 ## 6 PO150A463 Los Corralitos 2017-04-10 00:00:00 210 ## 7 PO150A434 Los Corralitos 2017-04-10 00:00:00 222 ## 8 PO150A435 Los Corralitos 2017-04-10 00:00:00 208 ## 9 PO150A675 Los Corralitos 2017-04-10 00:00:00 216 ## 10 PO150A681 Los Corralitos 2017-04-10 00:00:00 226 ## # ... with 250 more rows filter() asume que cada condicion se debe cumplir en simultaneo para que la observación sea seleccionada. Esto equivale a utilizar el operador &amp; (Y). En caso de querer seleccionar aquellos registros que cumple una u otra condicion se usa el operador | (O). Poniendo ! delante de la condicion se invierte la selección. # Operador &amp; filter(terneros, Procedencia == &#39;Los Corralitos&#39; &amp; Peso &gt; 200) ## # A tibble: 260 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 PO150A167 Los Corralitos 2017-04-10 00:00:00 224 ## 2 PO150A168 Los Corralitos 2017-04-10 00:00:00 234 ## 3 PO150A169 Los Corralitos 2017-04-10 00:00:00 204 ## 4 PO150A673 Los Corralitos 2017-04-10 00:00:00 246 ## 5 PO150A462 Los Corralitos 2017-04-10 00:00:00 238 ## 6 PO150A463 Los Corralitos 2017-04-10 00:00:00 210 ## 7 PO150A434 Los Corralitos 2017-04-10 00:00:00 222 ## 8 PO150A435 Los Corralitos 2017-04-10 00:00:00 208 ## 9 PO150A675 Los Corralitos 2017-04-10 00:00:00 216 ## 10 PO150A681 Los Corralitos 2017-04-10 00:00:00 226 ## # ... with 250 more rows # Operador | filter(terneros, Procedencia == &#39;Los Corralitos&#39; | Peso &gt; 200) ## # A tibble: 779 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 NR047A202 La Rosita 2017-04-06 00:00:00 204 ## 2 LH837F500 La Rosita 2017-04-06 00:00:00 208 ## 3 IY735C La Rosita 2017-04-06 00:00:00 242 ## 4 QW110A072 La Rosita 2017-04-06 00:00:00 218 ## 5 LH837F526 La Rosita 2017-04-06 00:00:00 208 ## 6 DS289A491 La Rosita 2017-04-06 00:00:00 204 ## 7 TL698HK39 La Rosita 2017-04-06 00:00:00 218 ## 8 LH837F538 La Rosita 2017-04-06 00:00:00 204 ## 9 IW751A017 La Rosita 2017-04-06 00:00:00 222 ## 10 NO133A004 Las Glicinas 2017-04-09 00:00:00 258 ## # ... with 769 more rows Con el operador %in% se puede especificar un rango de valores que deben cumplir. Por ejemplo terneros de Los Corralitos, Las Glicinas y Don Alberto # Indicando cada nombre filter(terneros, Procedencia == &#39;Los Corralitos&#39;, Procedencia == &#39;Las Glicinas&#39;, Procedencia == &#39;Don Alberto&#39;) ## # A tibble: 0 x 4 ## # ... with 4 variables: IDV &lt;chr&gt;, Procedencia &lt;chr&gt;, Fecha &lt;dttm&gt;, ## # Peso &lt;dbl&gt; # Más resumido con %in% filter(terneros, Procedencia %in% c(&#39;Los Corralitos&#39;, &#39;Las Glicinas&#39;, &#39;Don Alberto&#39;)) ## # A tibble: 1,138 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 SZ208I507 Las Glicinas 2017-04-09 00:00:00 152 ## 2 SZ208H993 Las Glicinas 2017-04-09 00:00:00 114 ## 3 SZ208H849 Las Glicinas 2017-04-09 00:00:00 158 ## 4 SZ208H777 Las Glicinas 2017-04-09 00:00:00 112 ## 5 GT542A562 Las Glicinas 2017-04-09 00:00:00 114 ## 6 OQ152A550 Las Glicinas 2017-04-09 00:00:00 182 ## 7 NO133A057 Las Glicinas 2017-04-09 00:00:00 168 ## 8 SZ208H888 Las Glicinas 2017-04-09 00:00:00 196 ## 9 OQ152A566 Las Glicinas 2017-04-09 00:00:00 176 ## 10 NO133A047 Las Glicinas 2017-04-09 00:00:00 180 ## # ... with 1,128 more rows 3.4.3 Encadenando operaciones (operador %&gt;%) dplyr importa el operador %&gt;% de otro paquete llamado magrittr. Este operador permite encadenar operaciones realizadas con los verbos. De este modo no hay que ir creando tablas intermedias o anidar funciones. El operador traduce como luego y se le de izquierda a derecha y se puede. Ejemplo: Reportar los IDV y peso de los terneros con más de 250 kg. Esto implicaría seleccionar las columnas de interés y luego filtrar la tabla o vice versa. # Creando tablas intermedias terneros2 &lt;- select(terneros, IDV, Peso) terneros2 ## # A tibble: 1,598 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NR047A202 204 ## 2 GN685B267 186 ## 3 AI101A751 182 ## 4 TM603C877 186 ## 5 TM420B797 186 ## 6 LH837F500 208 ## 7 NR047A217 170 ## 8 LH837F508 188 ## 9 GN685B256 172 ## 10 QW110A058 172 ## # ... with 1,588 more rows terneros2 &lt;- filter(terneros2, Peso &gt; 250) terneros2 ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NO133A004 258 ## 2 OQ152A456 258 ## 3 NO133A006 256 ## 4 OQ152A553 256 ## 5 PO150A166 290 ## 6 PO150A674 256 ## 7 PO150A656 272 ## 8 NO133A045 264 ## 9 PO150A571 264 ## 10 PO150A686 262 ## # ... with 65 more rows # Anidando filter(select(terneros, IDV, Peso), Peso &gt; 250) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NO133A004 258 ## 2 OQ152A456 258 ## 3 NO133A006 256 ## 4 OQ152A553 256 ## 5 PO150A166 290 ## 6 PO150A674 256 ## 7 PO150A656 272 ## 8 NO133A045 264 ## 9 PO150A571 264 ## 10 PO150A686 262 ## # ... with 65 more rows # Usando %&gt;% terneros %&gt;% select(IDV, Peso) %&gt;% filter(Peso &gt; 250) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NO133A004 258 ## 2 OQ152A456 258 ## 3 NO133A006 256 ## 4 OQ152A553 256 ## 5 PO150A166 290 ## 6 PO150A674 256 ## 7 PO150A656 272 ## 8 NO133A045 264 ## 9 PO150A571 264 ## 10 PO150A686 262 ## # ... with 65 more rows Con %&gt;% se puede omitir el nombre de la tabla sobre la que se está trabajando (bonus: menos tipeo). La última opción se lee: _tomar la tabla terneros, luego seleccionar las columnas IDV y Peso, luego filtrar los terneros con pesos mayores a 250 kg. El operador de encadenamiento es muy útil cuando se encadenan muchas operaciones. 3.4.4 Ordenar las filas Para ordenar según algun criterio aplicado a las columnas se usa arrange(). Por ejemplo, continuar con lo anterior pero mostrar ordenadospor peso. # Ordenar de menor a mayor terneros %&gt;% select(IDV, Peso) %&gt;% filter(Peso &gt; 250) %&gt;% arrange(Peso) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 PO150A546 252 ## 2 NS509H081 252 ## 3 PO15A710 252 ## 4 NO133A019 254 ## 5 PO150A784 254 ## 6 IA671B182 254 ## 7 IA671B176 254 ## 8 PO150A716 254 ## 9 NO133A006 256 ## 10 OQ152A553 256 ## # ... with 65 more rows Con decs(variable) se ordena de mayor a menor # Ordenar de mayor a menor terneros %&gt;% select(IDV, Peso) %&gt;% filter(Peso &gt; 250) %&gt;% arrange(desc(Peso)) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 PO150A679 384 ## 2 IA671B041 294 ## 3 MM429A932 292 ## 4 PO150A166 290 ## 5 PO150A763 288 ## 6 IA671B106 288 ## 7 NS509G964 286 ## 8 PO150A821 284 ## 9 IA671B045 282 ## 10 NO133A000 280 ## # ... with 65 more rows 3.4.5 Crear o transformar columnas Para crear nuevas columnas aplicando funciones a otras, o bien para transformar columnas se usa mutate(). Se pueden modificar más de una columna a la vez. Por ejemplo, suponiendo que interesa obtener el logaritmo natura de los pesos o elevar los pesos al cuadrado. terneros %&gt;% mutate(log_peso = log(Peso), peso2 = Peso**2) %&gt;% select(Peso, log_peso, peso2) # para que se vea mejor el resultado ## # A tibble: 1,598 x 3 ## Peso log_peso peso2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 204 5.32 41616 ## 2 186 5.23 34596 ## 3 182 5.20 33124 ## 4 186 5.23 34596 ## 5 186 5.23 34596 ## 6 208 5.34 43264 ## 7 170 5.14 28900 ## 8 188 5.24 35344 ## 9 172 5.15 29584 ## 10 172 5.15 29584 ## # ... with 1,588 more rows Esto no cambia el set de datos terneros ya que no se lo asignó a ningun objeto. Para sobreescribir o actualiza el set de datos terneros hay que asignarlo al mismo objeto. terneros &lt;- terneros %&gt;% mutate(log_peso = log(Peso), peso2 = Peso**2) Aclaración: Si se hubiese usado select() el set de datos terneros solamente contendría las columnas seleccionadas. Otro ejemplo más útil: calcular los z-scores de los peso (para ello se requiere calcular el promedio y desvio) y crear una columna que indique si es un outlier y luego reportar los que son outliers. terneros %&gt;% mutate(z = (Peso - mean(Peso))/sd(Peso), outlier = ifelse(abs(z) &gt; 3, &quot;si&quot;, &quot;no&quot;)) %&gt;% filter(outlier == &quot;si&quot;) %&gt;% select(IDV) ## # A tibble: 1 x 1 ## IDV ## &lt;chr&gt; ## 1 PO150A679 3.4.6 Resmuir datos Mediante summarise() se pueden aplicar funciones para resumir en un solo valor los valores de las columnas. Las funciones a aplicar deben devolver un único valor, por ejemplo mean(). Si usamos summary() esto devolverá 6 valores y dará error. terneros %&gt;% summarise(media = mean(Peso), sd = sd(Peso), n = n(), suma = sum(Peso), procedencias = n_distinct(Procedencia)) ## # A tibble: 1 x 5 ## media sd n suma procedencias ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 183. 37.2 1598 291882 7 Nuevamente estos resultados pueden asignarse a otro objeto o bien encadenarse con otras operaciones. Otro ejemplo, obtener la cantidad de terneros de cada procedencia terneros %&gt;% group_by(Procedencia) %&gt;% count() ## # A tibble: 7 x 2 ## # Groups: Procedencia [7] ## Procedencia n ## &lt;chr&gt; &lt;int&gt; ## 1 Don Alberto 69 ## 2 La Alameda 201 ## 3 La Estrella 118 ## 4 La Rosita 98 ## 5 La Segunda 43 ## 6 Las Glicinas 494 ## 7 Los Corralitos 575 Otro ejemplo más, cantidad de terneros de cada procedencia separados en mayor o menor a 200 kg terneros %&gt;% group_by(Procedencia, Peso &gt; 200) %&gt;% count() ## # A tibble: 14 x 3 ## # Groups: Procedencia, Peso &gt; 200 [14] ## Procedencia `Peso &gt; 200` n ## &lt;chr&gt; &lt;lgl&gt; &lt;int&gt; ## 1 Don Alberto FALSE 49 ## 2 Don Alberto TRUE 20 ## 3 La Alameda FALSE 136 ## 4 La Alameda TRUE 65 ## 5 La Estrella FALSE 112 ## 6 La Estrella TRUE 6 ## 7 La Rosita FALSE 89 ## 8 La Rosita TRUE 9 ## 9 La Segunda FALSE 5 ## 10 La Segunda TRUE 38 ## 11 Las Glicinas FALSE 428 ## 12 Las Glicinas TRUE 66 ## 13 Los Corralitos FALSE 315 ## 14 Los Corralitos TRUE 260 3.4.7 Agrupar (último pero no menos importante) El verbo group_by() es muy útil para aplicar operaciones en subgrupos y presentar todo junto (split-apply-combine). Lo que hace es indicar que en el data.frame hay una o más variables que conforman los grupos. Luego cada operación se aplica a esos subgrupos. Ejemplo: calcular media, desvio, n y suma para cada procedencia. terneros %&gt;% group_by(Procedencia) %&gt;% summarise(media = mean(Peso), sd = sd(Peso), n = n(), suma = sum(Peso)) ## # A tibble: 7 x 5 ## Procedencia media sd n suma ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Don Alberto 179. 26.9 69 12354 ## 2 La Alameda 190. 39.5 201 38192 ## 3 La Estrella 179. 14.2 118 21138 ## 4 La Rosita 180. 17.4 98 17620 ## 5 La Segunda 229. 24.8 43 9868 ## 6 Las Glicinas 160. 33.7 494 79254 ## 7 Los Corralitos 197. 35.8 575 113456 3.4.8 Muestrear El verbo sample_n() and sample_frac() son útiles para tomar muestras aleatorias (con o sin reposición) de un conjunto de observaciones. También se puede hacer por subgrupo! # Una muestra de 50 novillos muestra50 &lt;- terneros %&gt;% sample_n(50) muestra50 ## # A tibble: 50 x 6 ## IDV Procedencia Fecha Peso log_peso peso2 ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SZ208H769 Las Glicinas 2017-04-09 00:00:00 158 5.06 24964 ## 2 SZ208H939 Las Glicinas 2017-04-10 00:00:00 134 4.90 17956 ## 3 SZ208H896 Las Glicinas 2017-04-09 00:00:00 178 5.18 31684 ## 4 OH874D842 La Alameda 2017-04-18 00:00:00 182 5.20 33124 ## 5 NO133A060 Las Glicinas 2017-04-10 00:00:00 192 5.26 36864 ## 6 IY692B279 La Rosita 2017-04-06 00:00:00 154 5.04 23716 ## 7 PO150A773 Los Corralitos 2017-04-11 00:00:00 166 5.11 27556 ## 8 NS509G962 Los Corralitos 2017-04-12 00:00:00 190 5.25 36100 ## 9 NO133A014 Las Glicinas 2017-04-10 00:00:00 160 5.08 25600 ## 10 PO150A521 Los Corralitos 2017-04-11 00:00:00 178 5.18 31684 ## # ... with 40 more rows # Una muestra de 10 novillos de cada procedencia muestra_procedencia &lt;- terneros %&gt;% group_by(Procedencia) %&gt;% sample_n(10) muestra_procedencia ## # A tibble: 70 x 6 ## # Groups: Procedencia [7] ## IDV Procedencia Fecha Peso log_peso peso2 ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 GH738B325 Don Alberto 2017-04-20 00:00:00 184 5.21 33856 ## 2 GH738B381 Don Alberto 2017-04-20 00:00:00 204 5.32 41616 ## 3 GH738B376 Don Alberto 2017-04-20 00:00:00 192 5.26 36864 ## 4 GH738B350 Don Alberto 2017-04-20 00:00:00 200 5.30 40000 ## 5 GH738B349 Don Alberto 2017-04-20 00:00:00 204 5.32 41616 ## 6 GH738B390 Don Alberto 2017-04-20 00:00:00 206 5.33 42436 ## 7 GH738B343 Don Alberto 2017-04-20 00:00:00 166 5.11 27556 ## 8 GH738B383 Don Alberto 2017-04-20 00:00:00 150 5.01 22500 ## 9 GH738B386 Don Alberto 2017-04-20 00:00:00 158 5.06 24964 ## 10 GH738B365 Don Alberto 2017-04-20 00:00:00 164 5.10 26896 ## # ... with 60 more rows "],
=======
["aspectos-basicos-del-lenguaje-r.html", "Capítulo 2 Aspectos básicos del lenguaje R 2.1 Operadores matemáticos 2.2 Operadores lógicos 2.3 Variables y objetos 2.4 Funciones y argumentos 2.5 Vectores 2.6 Tipos de datos 2.7 Estructura de datos", " Capítulo 2 Aspectos básicos del lenguaje R En el capítulo anterior se introdujo la interfase básica de R (la consola) y la edición de secuencias de comandos mediante el uso de scripts. También se mostró la creación y uso de proyectos en RStudio. En este capítulo se abordarán los conceptos básicos del lenguaje R tales como operadores para representar operaciones matemáticas (suma, resta, etc), tipos de variables y objetos para representar los datos, y características generales de las funciones o comandos. 2.1 Operadores matemáticos En R las operaciones matemáticas básicas: suma (+), resta (-), división (/), producto (*) y potencia (^) se realizan usando los símbolos convencionales: Por ejemplo, \\(1 + \\left( 3 \\times 4 + \\dfrac{5 -2}{3} \\right)^2\\) en R es: 1 + (3 * 4 + (5 - 2)/3)^2 ## [1] 170 2.2 Operadores lógicos R permite evaluar expresiones lógicas: igual (==), distinto (!=), mayor que (&gt;), menor que (&lt;), mayor o igual que (&gt;=), menor o igual que (&lt;=). El resultado es TRUE (verdadero) o FALSE (falso) # 3 es igual a 4? 3 == 4 ## [1] FALSE # 5 es mayor o igual 3? 5 &gt;= 3 ## [1] TRUE # 2 es distinto que 2.5 2 != 2.5 ## [1] TRUE También se pueden combinar con los operadores intersección (&amp;), unión (|) y negación (!) # Devuelve FALSE ya que las dos condiciones no se cumplen a la vez 4 == 4 &amp; 5 == 6 ## [1] FALSE # Devuelve TRUE ya que una de la dos condiciones se cumple 4 == 4 | 5 == 6 ## [1] TRUE O con operaciones matemáticas… 4 * 2 == 8 ## [1] TRUE En este caso primero evalúa 4 * 2 y luego compara el resultado con 8 2.3 Variables y objetos En R practicamente todo puede almacenarse en un objeto, es decir, un espacio de la memoria asignado a almacenar información: una cifra, un conjunto de números, el resultado de un análisis, etc. También se denomina variables ya que su contenido puede cambiar. Con el simbolo &lt;- o bien = se pueden crear objetos o variables asignándoles información (números, letras, resultados de operaciones, etc) y para luego recuperarla y utilizarla en otros cálculos. # Crea la variable x y le asgina el valor 2 x &lt;- 2 x ## [1] 2 # Operación con variables 2 * x ## [1] 4 # Usar variables para definir nuevas variables y &lt;- 2 * x +1 y ## [1] 5 Aclaración: los nombres de las variables no deben empezar con números ni contener espacios. No pueden usarse operadores en los nombres pero puede usarse . o _. # Mal 2x &lt;- 3 mi variable &lt;- 3 # Bien x_2 &lt;- 3 x.2 &lt;- 3 x2 &lt;- 3 También R es sensibles a mayúsculas # Definir &#39;A&#39; y &#39;a&#39; A &lt;- 3 a &lt;- 5 # Verificar si &#39;A&#39; y &#39;a&#39; son lo mismo A == a ## [1] FALSE 2.4 Funciones y argumentos Las funciones dentro de R tienen la siguiente forma: nombre_funcion(arg1, arg2, ...), donde arg son los argumentos que toma cada función. Algunos argumentos toman valores por defecto otros hay que declararlos. Por ejemplo la función mean() tiene los argumentos: x para indicar el vector numérico sobre el cual queremos calcular el promedio trim para indicar la proporción de valores extremos excluir del cálculo (media truncada) na.rm para indicar si queremos o no excluir los valores NA. # Media truncada de 100 valores aleatorios y &lt;- runif(100) # Indicando los argumentos mean(x = y, trim = 0.1) ## [1] 0.5350915 # Sin indicar los argumentos mean(y, 0.1) ## [1] 0.5350915 En este último caso, el orden de los argumentos es clave ya que R asigna los valores en función de la posición 2.5 Vectores Son los objetos más simples a partir de los cuales se construyen otros tipos de objetos. Se crean utilizando la función c() para “combinar” datos del mismo tipo. x &lt;- c(13, 45, 67, 45) x ## [1] 13 45 67 45 Pueden contener un solo tipo de datos a la vez: numérico, texto, lógico. En el caso de mezcla de datos, R los va a coaccionar al tipo de datos más simple. Por ejemplo: si queremos crear un vector con 3 valores: lógico, numerico y texto, R va a asumir que todos los elementos son de tipo texto x &lt;- c(TRUE, 34, &quot;texto&quot;) x ## [1] &quot;TRUE&quot; &quot;34&quot; &quot;texto&quot; Los vectores están indexados y se puede acceder a sus elementos usando el operador [ ] e indicando el número de orden. Por ejemplo: # 3er elemento del vector x x[3] ## [1] &quot;texto&quot; 2.6 Tipos de datos 2.6.1 Numéricos (numeric) Números racionales (enteros o con coma). Los números enteros se tratan como numeric a menos que se los convierta con as.integer(). x &lt;- c(3, 4, 5) class(x) ## [1] &quot;numeric&quot; # Convertir a enteros y &lt;- as.integer(x) class(y) ## [1] &quot;integer&quot; Los datos numéricos permiten todas las operaciones algebráicas # La media aritmética de x mean(x) ## [1] 4 2.6.2 Texto (character) Cadenas de texto o número delimitadas por comillas (simples o dobles). x &lt;- c(&quot;hola&quot;, &#39;3&#39;, &quot;estadística1&quot;) class(x) ## [1] &quot;character&quot; Lógicamente, no se pueden realizar operaciones numéricas. Se pueden 2.6.3 Lógicos (logic) Condición verdadero (TRUE o T) o falso (FALSE o F) logico &lt;- c(T, F, T, TRUE, FALSE, F) logico ## [1] TRUE FALSE TRUE TRUE FALSE FALSE Ejemplo: ¿que números son mayores a 30? x &lt;- c(23, 43, 21, 34, 56, 3, 23, 3) x &gt; 30 ## [1] FALSE TRUE FALSE TRUE TRUE FALSE FALSE FALSE 2.6.4 Otros Los valores faltantes se simbolizan en R con NA. Indican que debería haber in valor pero que está faltando x &lt;- c(1, 2, 3, NA, 4) is.na(x) ## [1] FALSE FALSE FALSE TRUE FALSE A diferencia del NA, un valor de tipo NULL indica que no hay información y que tampoco se esperaba que la haya. x &lt;- c(1, 2, 3, NULL, 4) x ## [1] 1 2 3 4 Algunas operaciones matemáticas devuelven valores NaN cuando no están definidas, por ejemplo: 0/0 ## [1] NaN O bien valores infinitos: 1/0 ## [1] Inf 2.7 Estructura de datos 2.7.1 Matriz (matrix) Colección de vectores de igual longitud y mismo tipo de datos. Se crea con la función matrix(), o combinando filas o columnas de igual longitud con rbind() o cbind(). M &lt;- matrix(c(1, 2, 3, 4, 5, 6), ncol = 2) M ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 Se puede indexar usando [n, p] donde n es el numero de fila y p numero de columna. # Elemento m12 M[1,2] ## [1] 4 # Toda la columna 2 M[, 2] ## [1] 4 5 6 2.7.2 Listas (list) Generalización de los vectores ya que los elementos pueden ser de igual o diferente tipo de datos l &lt;- list(23, &quot;hola&quot;, TRUE) l ## [[1]] ## [1] 23 ## ## [[2]] ## [1] &quot;hola&quot; ## ## [[3]] ## [1] TRUE Se pueden indexar usando [[ ]] # El segundo elemento de l l[[2]] ## [1] &quot;hola&quot; Cada elemento a su vez puede ser cualquier objeto de los vistos anteriormente. 2.7.3 Hoja de datos (data.frame) Similares a las matrices pero cada columna puede ser de un tipo de dato diferente. Útil para guardar datos donde cada fila es un caso y cada columna una variable. trigo &lt;- data.frame( lote = 1:5, rendimiento = c(34, 36, 40, 28, 31), variedad = c(&#39;Escorpion&#39;, &#39;Escorpion&#39;, &#39;Yarara&#39;, &#39;Baguette 11&#39;, &#39;Tijetera&#39;) ) trigo ## lote rendimiento variedad ## 1 1 34 Escorpion ## 2 2 36 Escorpion ## 3 3 40 Yarara ## 4 4 28 Baguette 11 ## 5 5 31 Tijetera Se puede acceder a cada columna (vectores) con $ # Variedades trigo$variedad ## [1] Escorpion Escorpion Yarara Baguette 11 Tijetera ## Levels: Baguette 11 Escorpion Tijetera Yarara O indexar con indexar con [ ] # El bombre de la varidedad de la fila 2 trigo[2, 3] ## [1] Escorpion ## Levels: Baguette 11 Escorpion Tijetera Yarara # Todos los datos de la fila 2 trigo[2, ] ## lote rendimiento variedad ## 2 2 36 Escorpion # Lotes con rendimiento mayor a 35 qq/ha trigo[trigo$rendimiento &gt; 35, ] ## lote rendimiento variedad ## 2 2 36 Escorpion ## 3 3 40 Yarara 2.7.4 Factores (factor y ordered) Si los elementos de vector de tipo texto (character) representan niveles nominales (categorías), el objeto puede convertirse a factor de modo tal que los valores son reemplazados por un número que se asocia a los niveles del factor (ordenados alfabeticamente, a menos que se indique otra cosa). x &lt;- c(&#39;bajo&#39;, &#39;medio&#39;, &#39;alto&#39;, &#39;alto&#39;, &#39;bajo&#39;, &#39;bajo&#39;) x ## [1] &quot;bajo&quot; &quot;medio&quot; &quot;alto&quot; &quot;alto&quot; &quot;bajo&quot; &quot;bajo&quot; # factor nominal y &lt;- factor(x) y ## [1] bajo medio alto alto bajo bajo ## Levels: alto bajo medio as.numeric(y) ## [1] 2 3 1 1 2 2 En el ejemplo anterior, los valores eran bajo, medio y alto. Mediante la función estos valores pasaron al atributo levels y los datos fueron reemplazados por los identificadores 2, 3, y 1. Cuando los niveles tienen una jerarquía u orden, se puede especificar este tipo de relación mediante as.ordered() que convierte el factor en ordered agregando la relación entre los niveles # Factor ordinal z &lt;- factor(x, levels = c(&#39;bajo&#39;, &#39;medio&#39;, &#39;alto&#39;)) z &lt;- as.ordered(z) z ## [1] bajo medio alto alto bajo bajo ## Levels: bajo &lt; medio &lt; alto Los factores como cualquier vectore tambien se indexan con [ ]. "],
["introduccion-a-dplyr.html", "Capítulo 3 Introducción a dplyr 3.1 ¿Qué es dplyr? 3.2 ¿Cómo conseguir dplyr? 3.3 Verbos importantes de dplyr para recordar 3.4 dplyr en acción", " Capítulo 3 Introducción a dplyr En este capítulo y el siguiente se introducirán dos paquetes de R que están siendo ampliamente utilizados por la comunidad: dplyr y ggplot2. 3.1 ¿Qué es dplyr? dplyr es un paquete de R muy potente para la exploración, transformación y resumen de datos en formato de tabla con filas (observaciones) y columnas (variables). Es un componente de un conjunto de packages llamado tidyverse desarrollados por Hadley Wickham El paquete contiene un conjunto de funciones (o verbos) que realizan operaciones comunes para el manejo de datos tales como: filtrar filas, seleccionar columnas, re-ordenar filas, agregar o transformar columnas, resumir datos. También permite agrupar los datos facilitando la estrategia split-apply-combine, es decir, dividir (split) los datos según una variable de grupo, aplicar (apply) alguna transformación o resumen y combinar (combine) las partes para presentar los resultados. Si bien R base tiene funciones que realizan las mismas tareas (split(), subset(), apply(), sapply(), lapply(), tapply() and aggregate()), el paquete dplyr brinda una interface más consistente que permite trabajar de manera más facil con data.frame (tabla de datos) más que con vectores. 3.2 ¿Cómo conseguir dplyr? Para instalar por primera vez en la computadora: # Solo install.packages(&quot;dplyr&quot;) # O junto con la familia tidyverse install.packages(&quot;tidyverse&quot;) Lo anterior se debe realizar por única vez si el paquete no está previamente instalado en la máquina. Para usar las funciones en una sesion de trabajo hay que cargarlo con library(): # Solo library(&quot;dplyr&quot;) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union # O junto con la familia tidyverse library(&quot;tidyverse&quot;) ## ── Attaching packages ───────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ readr 1.1.1 ## ✔ tibble 1.4.2 ✔ purrr 0.2.5 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ ggplot2 3.0.0 ✔ forcats 0.3.0 ## ── Conflicts ──────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() R va a avisarnos en la consola que esta enmascarando (reemplazando) algunas funciones que ya estaban en el entorno, o bien el paquete nos devuelve algun mensaje. A menos que diga Error ..., eso está bien. 3.3 Verbos importantes de dplyr para recordar Toda la estrategia de trabajo con datos de dplyr se basa en 6 verbos: verbo descripción select() selecciona columnas (variables) filter() filtra o selecciona las filas (observaciones) arrange() re-ordena las filas mutate() crea nuevas columnas o modifica las preexistentes summarise() resumen los valores de una variable group_by() permite aplicar los verbos anteriores en subgrupos (split-apply-combine) sample_n() para tomar muestras aleatorias con o sin reposición En la mayoría de los casos la sintaxis es: function(que_datos, que_hacer_con_los_datos) En que_datos hay que poner el nombre del set de datos o data.frame (a menos que se use el operador %&gt;% para encadenar, mas adelante) y en que_hacer_con_los_datos indicar que operación, condicion, transformacion, etc aplicar a las filas y columnas. 3.4 dplyr en acción Para ilustrar el uso del paquete vamos a usar los datos contenidos en el archivo pesada_terneros.xlsx. # Cargar los datos con readxl library(readxl) terneros &lt;- read_excel(&quot;./data/pesada_terneros.xlsx&quot;) 3.4.1 Seleccionando variables Una tareas básicas cuando se exploran datos es la selección de columnas de interés (variables). Esto se lleva a cabo con select(). Para seleccionar las columnas Procedencia, IDV y Peso: # Sin asignar select(terneros, Procedencia, IDV, Peso) ## # A tibble: 1,598 x 3 ## Procedencia IDV Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita NR047A202 204 ## 2 La Rosita GN685B267 186 ## 3 La Rosita AI101A751 182 ## 4 La Rosita TM603C877 186 ## 5 La Rosita TM420B797 186 ## 6 La Rosita LH837F500 208 ## 7 La Rosita NR047A217 170 ## 8 La Rosita LH837F508 188 ## 9 La Rosita GN685B256 172 ## 10 La Rosita QW110A058 172 ## # ... with 1,588 more rows # Creando un nuevo set de datos mis_columnas &lt;- select(terneros, Procedencia, IDV, Peso) Por defecto, si no se asigna a un nuevo objeto, el resultado de la operación se imprime en la consola con la función print() la cual por defecto muestra las 10 primeras observaciones y la cantidad de columnas que entran en la pantalla. Aquellas columnas que no entran son indicadas al pie. Si quiero ver más registros se puede usar el argumento n = de print() print(mis_columnas, n = 15) ## # A tibble: 1,598 x 3 ## Procedencia IDV Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita NR047A202 204 ## 2 La Rosita GN685B267 186 ## 3 La Rosita AI101A751 182 ## 4 La Rosita TM603C877 186 ## 5 La Rosita TM420B797 186 ## 6 La Rosita LH837F500 208 ## 7 La Rosita NR047A217 170 ## 8 La Rosita LH837F508 188 ## 9 La Rosita GN685B256 172 ## 10 La Rosita QW110A058 172 ## 11 La Rosita LH837F497 188 ## 12 La Rosita TM420B803 180 ## 13 La Rosita LH837F514 198 ## 14 La Rosita II641B940 200 ## 15 La Rosita IY735C 242 ## # ... with 1,583 more rows Con n = &quot;all&quot; se imprimen todas (no se muestra por razones obvias) El orden en que aparecen las variables en el resultado es el orden que se utilizó al seleccionarlas. # El orden altera el producto select(terneros, Procedencia, IDV, Peso) ## # A tibble: 1,598 x 3 ## Procedencia IDV Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita NR047A202 204 ## 2 La Rosita GN685B267 186 ## 3 La Rosita AI101A751 182 ## 4 La Rosita TM603C877 186 ## 5 La Rosita TM420B797 186 ## 6 La Rosita LH837F500 208 ## 7 La Rosita NR047A217 170 ## 8 La Rosita LH837F508 188 ## 9 La Rosita GN685B256 172 ## 10 La Rosita QW110A058 172 ## # ... with 1,588 more rows También se puede usar los comnados starts_with(), ends_with(), contains(), etc (ver ?select_helpers) para más opciones). Para elegir varias columnas que tienen un patron sin tener que tipear todos los nombres. # Selecciona columnas que empiezan con P select(terneros, starts_with(&quot;P&quot;)) ## # A tibble: 1,598 x 2 ## Procedencia Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 La Rosita 204 ## 2 La Rosita 186 ## 3 La Rosita 182 ## 4 La Rosita 186 ## 5 La Rosita 186 ## 6 La Rosita 208 ## 7 La Rosita 170 ## 8 La Rosita 188 ## 9 La Rosita 172 ## 10 La Rosita 172 ## # ... with 1,588 more rows Para omitir algunas columnas en la seleccion se puede usar el - antes del nombre. # Selecciona columnas que empiezan con P select(terneros, -IDV, -starts_with(&quot;P&quot;)) ## # A tibble: 1,598 x 1 ## Fecha ## &lt;dttm&gt; ## 1 2017-04-06 00:00:00 ## 2 2017-04-06 00:00:00 ## 3 2017-04-06 00:00:00 ## 4 2017-04-06 00:00:00 ## 5 2017-04-06 00:00:00 ## 6 2017-04-06 00:00:00 ## 7 2017-04-06 00:00:00 ## 8 2017-04-06 00:00:00 ## 9 2017-04-06 00:00:00 ## 10 2017-04-06 00:00:00 ## # ... with 1,588 more rows 3.4.2 Seleccionando observaciones Otra tarea muy frecuente es seleccionar casos o observaciones que cumplan con alguna condición. Esto se lleva a cabo con filter(). Se pueden usar los operadores booleanos ==, &gt;, &lt;, &gt;=, &lt;=, !=, %in%) para crear pruebas o condiciones lógicas. Para seleccionar los terneros de Los Corralitos: # Sin asignar filter(terneros, Procedencia == &#39;Los Corralitos&#39;) ## # A tibble: 575 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 PO150A167 Los Corralitos 2017-04-10 00:00:00 224 ## 2 PO150A168 Los Corralitos 2017-04-10 00:00:00 234 ## 3 PO150A169 Los Corralitos 2017-04-10 00:00:00 204 ## 4 PO150A460 Los Corralitos 2017-04-10 00:00:00 196 ## 5 PO150A673 Los Corralitos 2017-04-10 00:00:00 246 ## 6 PO150A461 Los Corralitos 2017-04-10 00:00:00 196 ## 7 PO150A462 Los Corralitos 2017-04-10 00:00:00 238 ## 8 PO150A463 Los Corralitos 2017-04-10 00:00:00 210 ## 9 PO150A433 Los Corralitos 2017-04-10 00:00:00 174 ## 10 PO150A434 Los Corralitos 2017-04-10 00:00:00 222 ## # ... with 565 more rows # Creando un nuevo set de datos corralitos &lt;- filter(terneros, Procedencia == &#39;Los Corralitos&#39;) La seleccion se puede hacer por más de una condicion. Por ejemplo, seleccionar los de Los Corralitos que pesen más de 200 kg: filter(terneros, Procedencia == &#39;Los Corralitos&#39;, Peso &gt; 200) ## # A tibble: 260 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 PO150A167 Los Corralitos 2017-04-10 00:00:00 224 ## 2 PO150A168 Los Corralitos 2017-04-10 00:00:00 234 ## 3 PO150A169 Los Corralitos 2017-04-10 00:00:00 204 ## 4 PO150A673 Los Corralitos 2017-04-10 00:00:00 246 ## 5 PO150A462 Los Corralitos 2017-04-10 00:00:00 238 ## 6 PO150A463 Los Corralitos 2017-04-10 00:00:00 210 ## 7 PO150A434 Los Corralitos 2017-04-10 00:00:00 222 ## 8 PO150A435 Los Corralitos 2017-04-10 00:00:00 208 ## 9 PO150A675 Los Corralitos 2017-04-10 00:00:00 216 ## 10 PO150A681 Los Corralitos 2017-04-10 00:00:00 226 ## # ... with 250 more rows filter() asume que cada condicion se debe cumplir en simultaneo para que la observación sea seleccionada. Esto equivale a utilizar el operador &amp; (Y). En caso de querer seleccionar aquellos registros que cumple una u otra condicion se usa el operador | (O). Poniendo ! delante de la condicion se invierte la selección. # Operador &amp; filter(terneros, Procedencia == &#39;Los Corralitos&#39; &amp; Peso &gt; 200) ## # A tibble: 260 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 PO150A167 Los Corralitos 2017-04-10 00:00:00 224 ## 2 PO150A168 Los Corralitos 2017-04-10 00:00:00 234 ## 3 PO150A169 Los Corralitos 2017-04-10 00:00:00 204 ## 4 PO150A673 Los Corralitos 2017-04-10 00:00:00 246 ## 5 PO150A462 Los Corralitos 2017-04-10 00:00:00 238 ## 6 PO150A463 Los Corralitos 2017-04-10 00:00:00 210 ## 7 PO150A434 Los Corralitos 2017-04-10 00:00:00 222 ## 8 PO150A435 Los Corralitos 2017-04-10 00:00:00 208 ## 9 PO150A675 Los Corralitos 2017-04-10 00:00:00 216 ## 10 PO150A681 Los Corralitos 2017-04-10 00:00:00 226 ## # ... with 250 more rows # Operador | filter(terneros, Procedencia == &#39;Los Corralitos&#39; | Peso &gt; 200) ## # A tibble: 779 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 NR047A202 La Rosita 2017-04-06 00:00:00 204 ## 2 LH837F500 La Rosita 2017-04-06 00:00:00 208 ## 3 IY735C La Rosita 2017-04-06 00:00:00 242 ## 4 QW110A072 La Rosita 2017-04-06 00:00:00 218 ## 5 LH837F526 La Rosita 2017-04-06 00:00:00 208 ## 6 DS289A491 La Rosita 2017-04-06 00:00:00 204 ## 7 TL698HK39 La Rosita 2017-04-06 00:00:00 218 ## 8 LH837F538 La Rosita 2017-04-06 00:00:00 204 ## 9 IW751A017 La Rosita 2017-04-06 00:00:00 222 ## 10 NO133A004 Las Glicinas 2017-04-09 00:00:00 258 ## # ... with 769 more rows Con el operador %in% se puede especificar un rango de valores que deben cumplir. Por ejemplo terneros de Los Corralitos, Las Glicinas y Don Alberto # Indicando cada nombre filter(terneros, Procedencia == &#39;Los Corralitos&#39;, Procedencia == &#39;Las Glicinas&#39;, Procedencia == &#39;Don Alberto&#39;) ## # A tibble: 0 x 4 ## # ... with 4 variables: IDV &lt;chr&gt;, Procedencia &lt;chr&gt;, Fecha &lt;dttm&gt;, ## # Peso &lt;dbl&gt; # Más resumido con %in% filter(terneros, Procedencia %in% c(&#39;Los Corralitos&#39;, &#39;Las Glicinas&#39;, &#39;Don Alberto&#39;)) ## # A tibble: 1,138 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 SZ208I507 Las Glicinas 2017-04-09 00:00:00 152 ## 2 SZ208H993 Las Glicinas 2017-04-09 00:00:00 114 ## 3 SZ208H849 Las Glicinas 2017-04-09 00:00:00 158 ## 4 SZ208H777 Las Glicinas 2017-04-09 00:00:00 112 ## 5 GT542A562 Las Glicinas 2017-04-09 00:00:00 114 ## 6 OQ152A550 Las Glicinas 2017-04-09 00:00:00 182 ## 7 NO133A057 Las Glicinas 2017-04-09 00:00:00 168 ## 8 SZ208H888 Las Glicinas 2017-04-09 00:00:00 196 ## 9 OQ152A566 Las Glicinas 2017-04-09 00:00:00 176 ## 10 NO133A047 Las Glicinas 2017-04-09 00:00:00 180 ## # ... with 1,128 more rows 3.4.3 Encadenando operaciones (operador %&gt;%) dplyr importa el operador %&gt;% de otro paquete llamado magrittr. Este operador permite encadenar operaciones realizadas con los verbos. De este modo no hay que ir creando tablas intermedias o anidar funciones. El operador traduce como luego y se le de izquierda a derecha y se puede. Ejemplo: Reportar los IDV y peso de los terneros con más de 250 kg. Esto implicaría seleccionar las columnas de interés y luego filtrar la tabla o vice versa. # Creando tablas intermedias terneros2 &lt;- select(terneros, IDV, Peso) terneros2 ## # A tibble: 1,598 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NR047A202 204 ## 2 GN685B267 186 ## 3 AI101A751 182 ## 4 TM603C877 186 ## 5 TM420B797 186 ## 6 LH837F500 208 ## 7 NR047A217 170 ## 8 LH837F508 188 ## 9 GN685B256 172 ## 10 QW110A058 172 ## # ... with 1,588 more rows terneros2 &lt;- filter(terneros2, Peso &gt; 250) terneros2 ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NO133A004 258 ## 2 OQ152A456 258 ## 3 NO133A006 256 ## 4 OQ152A553 256 ## 5 PO150A166 290 ## 6 PO150A674 256 ## 7 PO150A656 272 ## 8 NO133A045 264 ## 9 PO150A571 264 ## 10 PO150A686 262 ## # ... with 65 more rows # Anidando filter(select(terneros, IDV, Peso), Peso &gt; 250) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NO133A004 258 ## 2 OQ152A456 258 ## 3 NO133A006 256 ## 4 OQ152A553 256 ## 5 PO150A166 290 ## 6 PO150A674 256 ## 7 PO150A656 272 ## 8 NO133A045 264 ## 9 PO150A571 264 ## 10 PO150A686 262 ## # ... with 65 more rows # Usando %&gt;% terneros %&gt;% select(IDV, Peso) %&gt;% filter(Peso &gt; 250) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 NO133A004 258 ## 2 OQ152A456 258 ## 3 NO133A006 256 ## 4 OQ152A553 256 ## 5 PO150A166 290 ## 6 PO150A674 256 ## 7 PO150A656 272 ## 8 NO133A045 264 ## 9 PO150A571 264 ## 10 PO150A686 262 ## # ... with 65 more rows Con %&gt;% se puede omitir el nombre de la tabla sobre la que se está trabajando (bonus: menos tipeo). La última opción se lee: _tomar la tabla terneros, luego seleccionar las columnas IDV y Peso, luego filtrar los terneros con pesos mayores a 250 kg. El operador de encadenamiento es muy útil cuando se encadenan muchas operaciones. 3.4.4 Ordenar las filas Para ordenar según algun criterio aplicado a las columnas se usa arrange(). Por ejemplo, continuar con lo anterior pero mostrar ordenadospor peso. # Ordenar de menor a mayor terneros %&gt;% select(IDV, Peso) %&gt;% filter(Peso &gt; 250) %&gt;% arrange(Peso) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 PO150A546 252 ## 2 NS509H081 252 ## 3 PO15A710 252 ## 4 NO133A019 254 ## 5 PO150A784 254 ## 6 IA671B182 254 ## 7 IA671B176 254 ## 8 PO150A716 254 ## 9 NO133A006 256 ## 10 OQ152A553 256 ## # ... with 65 more rows Con decs(variable) se ordena de mayor a menor # Ordenar de mayor a menor terneros %&gt;% select(IDV, Peso) %&gt;% filter(Peso &gt; 250) %&gt;% arrange(desc(Peso)) ## # A tibble: 75 x 2 ## IDV Peso ## &lt;chr&gt; &lt;dbl&gt; ## 1 PO150A679 384 ## 2 IA671B041 294 ## 3 MM429A932 292 ## 4 PO150A166 290 ## 5 PO150A763 288 ## 6 IA671B106 288 ## 7 NS509G964 286 ## 8 PO150A821 284 ## 9 IA671B045 282 ## 10 NO133A000 280 ## # ... with 65 more rows 3.4.5 Crear o transformar columnas Para crear nuevas columnas aplicando funciones a otras, o bien para transformar columnas se usa mutate(). Se pueden modificar más de una columna a la vez. Por ejemplo, suponiendo que interesa obtener el logaritmo natura de los pesos o elevar los pesos al cuadrado. terneros %&gt;% mutate(log_peso = log(Peso), peso2 = Peso**2) %&gt;% select(Peso, log_peso, peso2) # para que se vea mejor el resultado ## # A tibble: 1,598 x 3 ## Peso log_peso peso2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 204 5.32 41616 ## 2 186 5.23 34596 ## 3 182 5.20 33124 ## 4 186 5.23 34596 ## 5 186 5.23 34596 ## 6 208 5.34 43264 ## 7 170 5.14 28900 ## 8 188 5.24 35344 ## 9 172 5.15 29584 ## 10 172 5.15 29584 ## # ... with 1,588 more rows Esto no cambia el set de datos terneros ya que no se lo asignó a ningun objeto. Para sobreescribir o actualiza el set de datos terneros hay que asignarlo al mismo objeto. terneros &lt;- terneros %&gt;% mutate(log_peso = log(Peso), peso2 = Peso**2) Aclaración: Si se hubiese usado select() el set de datos terneros solamente contendría las columnas seleccionadas. Otro ejemplo más útil: calcular los z-scores de los peso (para ello se requiere calcular el promedio y desvio) y crear una columna que indique si es un outlier y luego reportar los que son outliers. terneros %&gt;% mutate(z = (Peso - mean(Peso))/sd(Peso), outlier = ifelse(abs(z) &gt; 3, &quot;si&quot;, &quot;no&quot;)) %&gt;% filter(outlier == &quot;si&quot;) %&gt;% select(IDV) ## # A tibble: 1 x 1 ## IDV ## &lt;chr&gt; ## 1 PO150A679 3.4.6 Resmuir datos Mediante summarise() se pueden aplicar funciones para resumir en un solo valor los valores de las columnas. Las funciones a aplicar deben devolver un único valor, por ejemplo mean(). Si usamos summary() esto devolverá 6 valores y dará error. terneros %&gt;% summarise(media = mean(Peso), sd = sd(Peso), n = n(), suma = sum(Peso), procedencias = n_distinct(Procedencia)) ## # A tibble: 1 x 5 ## media sd n suma procedencias ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 183. 37.2 1598 291882 7 Nuevamente estos resultados pueden asignarse a otro objeto o bien encadenarse con otras operaciones. Otro ejemplo, obtener la cantidad de terneros de cada procedencia terneros %&gt;% group_by(Procedencia) %&gt;% count() ## # A tibble: 7 x 2 ## # Groups: Procedencia [7] ## Procedencia n ## &lt;chr&gt; &lt;int&gt; ## 1 Don Alberto 69 ## 2 La Alameda 201 ## 3 La Estrella 118 ## 4 La Rosita 98 ## 5 La Segunda 43 ## 6 Las Glicinas 494 ## 7 Los Corralitos 575 Otro ejemplo más, cantidad de terneros de cada procedencia separados en mayor o menor a 200 kg terneros %&gt;% group_by(Procedencia, Peso &gt; 200) %&gt;% count() ## # A tibble: 14 x 3 ## # Groups: Procedencia, Peso &gt; 200 [14] ## Procedencia `Peso &gt; 200` n ## &lt;chr&gt; &lt;lgl&gt; &lt;int&gt; ## 1 Don Alberto FALSE 49 ## 2 Don Alberto TRUE 20 ## 3 La Alameda FALSE 136 ## 4 La Alameda TRUE 65 ## 5 La Estrella FALSE 112 ## 6 La Estrella TRUE 6 ## 7 La Rosita FALSE 89 ## 8 La Rosita TRUE 9 ## 9 La Segunda FALSE 5 ## 10 La Segunda TRUE 38 ## 11 Las Glicinas FALSE 428 ## 12 Las Glicinas TRUE 66 ## 13 Los Corralitos FALSE 315 ## 14 Los Corralitos TRUE 260 3.4.7 Agrupar (último pero no menos importante) El verbo group_by() es muy útil para aplicar operaciones en subgrupos y presentar todo junto (split-apply-combine). Lo que hace es indicar que en el data.frame hay una o más variables que conforman los grupos. Luego cada operación se aplica a esos subgrupos. Ejemplo: calcular media, desvio, n y suma para cada procedencia. terneros %&gt;% group_by(Procedencia) %&gt;% summarise(media = mean(Peso), sd = sd(Peso), n = n(), suma = sum(Peso)) ## # A tibble: 7 x 5 ## Procedencia media sd n suma ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Don Alberto 179. 26.9 69 12354 ## 2 La Alameda 190. 39.5 201 38192 ## 3 La Estrella 179. 14.2 118 21138 ## 4 La Rosita 180. 17.4 98 17620 ## 5 La Segunda 229. 24.8 43 9868 ## 6 Las Glicinas 160. 33.7 494 79254 ## 7 Los Corralitos 197. 35.8 575 113456 3.4.8 Muestrear El verbo sample_n() and sample_frac() son útiles para tomar muestras aleatorias (con o sin reposición) de un conjunto de observaciones. También se puede hacer por subgrupo! # Una muestra de 50 novillos muestra50 &lt;- terneros %&gt;% sample_n(50) muestra50 ## # A tibble: 50 x 6 ## IDV Procedencia Fecha Peso log_peso peso2 ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SZ208H912 Las Glicinas 2017-04-10 00:00:00 154 5.04 23716 ## 2 QX675H704 La Estrella 2017-04-12 00:00:00 176 5.17 30976 ## 3 SZ208H987 Las Glicinas 2017-04-10 00:00:00 140 4.94 19600 ## 4 SZ208H780 Las Glicinas 2017-04-10 00:00:00 132 4.88 17424 ## 5 SZ208H946 Las Glicinas 2017-04-09 00:00:00 136 4.91 18496 ## 6 OQ152A492 Las Glicinas 2017-04-10 00:00:00 192 5.26 36864 ## 7 PO150A832 Los Corralitos 2017-04-11 00:00:00 200 5.30 40000 ## 8 QX675H964 La Estrella 2017-04-12 00:00:00 198 5.29 39204 ## 9 PO150A786 Los Corralitos 2017-04-11 00:00:00 130 4.87 16900 ## 10 OE528B861 La Alameda 2017-04-18 00:00:00 162 5.09 26244 ## # ... with 40 more rows # Una muestra de 10 novillos de cada procedencia muestra_procedencia &lt;- terneros %&gt;% group_by(Procedencia) %&gt;% sample_n(10) muestra_procedencia ## # A tibble: 70 x 6 ## # Groups: Procedencia [7] ## IDV Procedencia Fecha Peso log_peso peso2 ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 GH738B345 Don Alberto 2017-04-20 00:00:00 162 5.09 26244 ## 2 GH738B337 Don Alberto 2017-04-20 00:00:00 202 5.31 40804 ## 3 GH738B326 Don Alberto 2017-04-20 00:00:00 182 5.20 33124 ## 4 GH738B383 Don Alberto 2017-04-20 00:00:00 150 5.01 22500 ## 5 GH738B327 Don Alberto 2017-04-20 00:00:00 148 5.00 21904 ## 6 GH378B378 Don Alberto 2017-04-20 00:00:00 148 5.00 21904 ## 7 GH738B346 Don Alberto 2017-04-20 00:00:00 208 5.34 43264 ## 8 GH738B349 Don Alberto 2017-04-20 00:00:00 204 5.32 41616 ## 9 GH738B362 Don Alberto 2017-04-20 00:00:00 210 5.35 44100 ## 10 GH738B360 Don Alberto 2017-04-20 00:00:00 210 5.35 44100 ## # ... with 60 more rows "],
>>>>>>> 2b0e4b8b82a98be964f6bc149e4b8d229d9a1e51
["introduccion-a-ggplot2.html", "Capítulo 4 Introducción a ggplot2 4.1 Sistemas de gráficos en R 4.2 ¿Cómo conseguir ggplot2? 4.3 Partes básicas de un gráfico 4.4 Todo en un solo paso", " Capítulo 4 Introducción a ggplot2 4.1 Sistemas de gráficos en R R cuenta con tres sistemas para graficar: El básico o base plot system, que viene por defecto y tiene funciones para hacer gráficos simples plot() y otras (hist(), barplot(), boxplot(), etc). Usa un enfoque lienzo y lapiz donde cada capa se tiene que ir agregando una por una. El para gráficos más complejos (con subgrupos o multipanel) requiere programar más. Una desventaja es la sintaxis poco consistente. El paquete lattice desarrollado por Deepayan Sarkar, que implementa graficos tipo trellis (multipanel). Al contraro de el paquete base, lattice tiene un sintaxis más coherente y en vez de tener un enfoque lienzo y lápiz, todos los componentes del gráfico se declaran en una función. muy conveniente para graficos condicionales pero complicada para combinar gráficos o hacer ajustes finos. El paquete ggplot2, desarrollado por Hadley Wickham, está basado en la filosofía Gramática de gráficos (grammar of graphics). Combina los dos enfoques: lienzo-lápiz y función. Uno provee los datos, indica que variables asignar a las estéticas (ejes, escalas, colores, símbolos) y tipo de gráfico hacer y ggplot2 se encarga del resto. Puede ir agregando capas. Es muy potente para la exploración y visualización de datos en formato de tabla con filas (observaciones) y columnas (variables). 4.2 ¿Cómo conseguir ggplot2? Para instalar por primera vez en la computadora: # Solo install.packages(&quot;ggplot2&quot;) # O junto con la familia tidyverse install.packages(&quot;tidyverse&quot;) Lo anterior se debe realizar por única vez si el paquete no está previamente instalado en la máquina. Para usar las funciones en una sesion de trabajo hay que cargarlo con library(): # Solo library(&quot;ggplot2&quot;) # O junto con la familia tidyverse library(&quot;tidyverse&quot;) R va a avisarnos en la consola que esta enmascarando (reemplazando) algunas funciones que ya estaban en el entorno, o bien el paquete nos devuelve algun mensaje. A menos que diga Error ..., eso está bien. 4.3 Partes básicas de un gráfico Si bien es dificil resumir como trabaja ggplot2 en un párrafo, la estrategia para graficar puede resumirse así: Se comienza con ggplot() para suministrar el set de datos y se definen. Se definen los parámetros estéticos, i.e. que variables van a los ejes, colores, escales, etc., con la aes(). En este caso el set de datos es terneros y queremos hacer un histograma. En el eje x vamos a indicar el Peso y en relleno vamos a indicar la Procedencia library(readxl) terneros &lt;- read_excel(&quot;./data/pesada_terneros.xlsx&quot;) # Iniciar objeto p &lt;- ggplot(terneros, aes(x = Peso, fill = Procedencia)) p Luego agregar las capas o layers con las geometrías geom_* que uno quiere graficar (tipo de gráfico) En este caso como es un histograma entonces geom_histogram() es la geometría indicada. # Iniciar objeto p &lt;- p + geom_histogram() p ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Si es necesario ajustar la escala de colores con scales_. En este caso vamos a probar un gradiente de colores con scale_color_brewer(). # Iniciar objeto p &lt;- p + scale_fill_brewer(&quot;RdYlGn&quot;, type = &quot;div&quot;) p ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Suponiendo que queremos dividir en paneles se puede usar factes_wrap(). En este caso agregamos Fecha como facets. p &lt;- p + facet_wrap(~ Fecha) p ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Se puede modificar los ejes de coordenadas con las funciones de tipo coords_(). Por ejemplo, para ilustrar vamos a rotar el gráfico. p &lt;- p + coord_flip() p ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Por último se pueden modificar los títulos de los ejes y otros detalles como la leyenda p &lt;- p + labs(x = &quot;Peso (kg)&quot;, y = &quot;frecuencia&quot;) p ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. p &lt;- p + guides(fill = guide_legend(title = &quot;Procedencia&quot;)) p ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 4.4 Todo en un solo paso Anteriormente fuimos agregando partes al gráfico. Una característica de ggplot2 es que mediante + se pueden ir combinando los comandos. p &lt;- ggplot(terneros, aes(x = Peso, fill = Procedencia)) + geom_histogram() + scale_fill_brewer(&quot;RdYlGn&quot;, type = &quot;div&quot;) + facet_wrap(~ Fecha) + coord_flip() + labs(x = &quot;Peso (kg)&quot;, y = &quot;frecuencia&quot;) + guides(fill = guide_legend(title = &quot;Procedencia&quot;)) p ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. O más avanzado, agregando estadísticas de resumen calculadas # Agregar linea representando medias por procedencia y fecha library(dplyr) med &lt;- terneros %&gt;% group_by(Procedencia, Fecha) %&gt;% summarise(media = mean(Peso)) med ## # A tibble: 12 x 3 ## # Groups: Procedencia [?] ## Procedencia Fecha media ## &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 Don Alberto 2017-04-20 00:00:00 179. ## 2 La Alameda 2017-04-18 00:00:00 190. ## 3 La Estrella 2017-04-12 00:00:00 179. ## 4 La Rosita 2017-04-06 00:00:00 180. ## 5 La Rosita 2017-04-10 00:00:00 182 ## 6 La Segunda 2017-04-20 00:00:00 229. ## 7 Las Glicinas 2017-04-09 00:00:00 163. ## 8 Las Glicinas 2017-04-10 00:00:00 159. ## 9 Los Corralitos 2017-04-10 00:00:00 198. ## 10 Los Corralitos 2017-04-11 00:00:00 196. ## 11 Los Corralitos 2017-04-12 00:00:00 200. ## 12 Los Corralitos 2017-04-20 00:00:00 182 # Combinar en el grafico (coord_cartesian para que vuelva a horizontal) p + coord_cartesian() + geom_vline(data = med, aes(xintercept = media)) ## Coordinate system already present. Adding new coordinate system, which will replace the existing one. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. "],
["revision-de-estadistica-basica.html", "Capítulo 5 Revisión de estadística básica 5.1 ¿Qué es la estadística? 5.2 Variables 5.3 Población y muestra 5.4 Estadística descriptiva 5.5 Variabiles aleatorias y distribuciones de probabilidades 5.6 Intervalos de Confianza: generalidades 5.7 Test hipotesis: generalidades 5.8 Comparación de dos poblaciones", " Capítulo 5 Revisión de estadística básica En este capítulo revisaremos algunos conceptos y términos estadísticos básicos que necesitaremos para el entender el diseño y análisis estadístico de datos provenientes de estudios observacionales y experimentales. En concreto revisaremos: Qué es y para qué sirve la Estadística Variables y tipos de datos Población y muestra Estadística descriptiva Varibales aleatorias y distribuciones de probabilidades Inferencia estadística: intervalos de confianza y prueba de hipótesis. 5.1 ¿Qué es la estadística? Existen muchas definiciones de Estadística, tantas como libros consultemos. Según Ott y Longnecker (2016), la estadística es la ciencia del diseño de estudios o experimentos, recolección de datos y modelado/análisis de los mismos para la toma de decisiones o descubrimiento de nuevo conocimiento cuando la información disponible es limitada y variable. En resumen, la estadística es la ciencia del aprendizaje a partir de los datos (learning from data) y está muy emparentada con la aplicación del método científico. Según este enfoque, el proceso de aprender a partir de los datos implica las siguientes etapas: Definición del problema de estudio. Todo estudio o investigación surge de una pregunta de investigación, un interrogante sobre nuestro objeto de estudio que no ha sido respondido aún con la información existente. Esto motiva la búsqueda de más información (nuevos experimentos o muestreos) para verificar las posibles respuestas o modelos que nos permitan representarlo (hipótesis). Entonces, a partir de la identificación del problema o pregunta de estudio ponemos de relieve cuáles son las variables que intervienen en el proceso, cuáles hay que controlar y cuáles hay que alterar para ver la respuesta, cuál es la información que debemos recolectar, que tipo de datos se van a trabajar, etc. Recolección de los datos. Una vez definido el problema de estudio, necesitamos determinar de qué manera se colectará la información relevante. Para ello debemos diseñar muestreos o experimentos que permitan de manera costo efectiva obtener la mayor cantidad de información empleando el menor tiempo y dinero para lograr responder de manera precisa la pregunta que originó el estudio. La estadísitca brinda herramientas para el esto. Resumen de la información. con los datos en mano debemos organizadorlos y resumirlos mediante técnicas núméricas o gráficas para facilitar su exploración y el reconocimiento de las principales características o patrones de los mismos (tendencias, variabilidad, anomalías, etc.). La estadística descriptiva brinda las herramientas necesarias para la descripción de la información proveniente de muestreos o experimentos. Análisis, interpretación y comunicación de los resultados. Los datos obtenidos son una pequeña parte (muestra) de un conjunto más grande (población) el cual es imposible observar en su totalidad. Debemos analizar la información de la muestra para realizar generalizaciones y poder interpretar los resultados en la población. La estadística inferencial brinda herramientas para estimar y valorar los modelos definidos en la Etapa 1 a la luz de los datos recolectados en la Etapa 2 considerando la variabilidad del proceso que los generó. 5.2 Variables Las variables son características de interés que se observan o miden en la unidad de observación más pequeña. Al contrario que las constantes, las variables toman diferentes valores de una individuo a otro, i.e. varían. Podemos clasificar las variables según el tipo de datos e información que contienen. 5.2.1 Tipos de datos Según el tipo de datos, las variables son: Cualitativas: que expresan una cualidad o atributo no numéricos. e.g. color de pelo, sexo, estatus sanitario, estado fenológico. Cuantitativas: que expresan una cantidad discreta (e.g. número de ramas, número de insectos) o contínua (e.g. peso de granos, contenido de MO del suelo). 5.2.2 Escala de medición Según la cantidad de información que contienen (de menor a mayor) las variables se clasifican en: Nominal: cualitativa (el número de identificación o RP de una vaca) Ordinal: cualitativa con orden (posición en el ranking del control lechero) De intervalo: cuantitativa, orden y distancias (fecha del último parto) De razón: cuantitativa, orden, distancia y proporciones (días desde el último parto) La escala de medición determina la cantidad de información que tienen y qué métodos podemos aplicar. Siempre podemos analizar variables más completas con técnicas para variables más simples. No obstante, este procedimiento implica pérdida información que puede ser relevante para responder la pregunta de investigación. Por ejemplo, una variable numérica de intervalo o razón podemos convertirla en nominal u ordinal generando intervalos de clases y contabilizar las frecuencias de cada clase. Por el contrario, las variables más simples no pueden ser analizadas con técnicas diseñadas para variables más completas. Ejemplo: no podemos obtener el promedio de una variable nominal como el color de pelo. 5.3 Población y muestra Desde el punto de vista estadístico, una Población es la totalidad de las unidades u observaciones individuales sobre la cuales queremos realizar la inferencia. Está definida en el tiempo y espacio y se caracteriza por sus parámetros, i.e. la media \\(\\mu\\). Las poblaciones pueden ser finitas, i.e. podemos contar la totalidad de elementos que contienen, o infinita, i.e. no los podemos contar. En la mayoría de los casos, los métodos estadísticos asumen que la población es infinita o finitas pero tan grandes que a los efectos prácticos puede asumirse que son infinitas. Por su parte, una muestra es un subconjunto de individuos u observaciones individuales que elegimos de la población. Las muestras son finitas y se caracterizan por sus estadísticos que son la versión muestral de los parámetros poblacionales, i.e. la media muestral \\(\\bar{y}\\). Si el procedimiento que utilizamos para obtener la muestra es aleatorio entonces podemos asumir que la muestra tendrá las mismas propiedades que la población y por lo tanto podemos usar dicha información para inferencia características de la poblaicón. En el siguiente gráfico resume el concepto general de la inferencia estadística. Figure 5.1: Esquema del proceso de inferencia estadística Supongamos que queremos conocer el valor medio de las alturas (parámetro) en m de plantas de maíz de un lote de 50 has, i.e. \\(\\mu = ?\\). El conjunto más grande denominado Población contiene las alturas en m de todas las plantas de maíz del lote en estudio y sobre el que se quiere hacer la inferencia (los \\(\\dots\\) indican que en el gráfico no están representados todos los valores). Cada planta es una unidad de muestreo porque la elegimos individualmente, y una unidad observacional porque a cada planta le medimos la altura (observación). Aquellas alturas en rojo corresponden a las 6 plantas que seleccionamos mediante un muestreo aleatorio para componer la muestra (\\(n = 6\\)). La altura promedio de las plantas de la muestra (estadístico) es \\(\\bar{y} = 1.728\\). Dado que el muestreo fue realizado al azar, el estadístico calculado a partir de la muestra brinda información sobre lo que pasa a nivel poblacional (\\(\\mu\\)). A su vez, la aleatoriedad del muestreo determina que si repitieramos el muestreo de 6 unidades muchas veces, el estadístico muestral tomaría distintos valores cada vez ya que es una variable aleatoria. Finalmente, a partir de la distribución de probabilidades asociada a los posibles valores que tomaría el estadístico muestral podemos realizar la inferencia sobre el parámetro poblacional incorporando la variabilidad del muestreo. 5.4 Estadística descriptiva La Estadística Descriptiva la rama de la Estadísica que comprende las técnicas y métodos para organizar, resumir y describir conjuntos de datos de distinto tipo recolectados en muestreos o censos. 5.4.1 Tablas de frecuencias Conocer la distribución de los valores de las variables en estudio es importante para examinar algunas características tales como la tendencia central, la dispersión, presencia de valores atípicos, etc. Una forma de examinar al distribución es mediante tablas de frecuencias que consisten en el listado de los valores de la variable (individuales o agrupados en clases) y sus frecuencias o conteos correspondientes. Es útil para resumir variables categóricas, discretas o conjuntos de datos cuantitativos contínuos grandes \\(n &gt; 25\\). Las frecuencias representan el número de veces que un valor o clase está representado en la muestra o población. Para ejemplificar la construcción de tablas de frecuencias en R usaremos datos de pesaje de terneros de un establecimiento ganadero del norte de Santa Fe. Los datos encuentran en el archivo pesada_terneros.xlsx. # Cargar los datos library(readxl) terneros &lt;- read_excel(&quot;pesada_terneros.xlsx&quot;) terneros ## # A tibble: 1,598 x 4 ## IDV Procedencia Fecha Peso ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 NR047A202 La Rosita 2017-04-06 00:00:00 204 ## 2 GN685B267 La Rosita 2017-04-06 00:00:00 186 ## 3 AI101A751 La Rosita 2017-04-06 00:00:00 182 ## 4 TM603C877 La Rosita 2017-04-06 00:00:00 186 ## 5 TM420B797 La Rosita 2017-04-06 00:00:00 186 ## 6 LH837F500 La Rosita 2017-04-06 00:00:00 208 ## 7 NR047A217 La Rosita 2017-04-06 00:00:00 170 ## 8 LH837F508 La Rosita 2017-04-06 00:00:00 188 ## 9 GN685B256 La Rosita 2017-04-06 00:00:00 172 ## 10 QW110A058 La Rosita 2017-04-06 00:00:00 172 ## # ... with 1,588 more rows Primero hay que definir el número de *intervalos de clases y sus límites de clase (inferior \\(\\text{LI}\\) y superior \\(\\text{LS}\\)). Generalmente se consideran semiabiertos a derecha [ ) y si bien no hay un criterio estricto para determinar el número de clases, se recomiendan entre 5 y 20 clases de igual amplitud es adecuado. El número depende de la dispersión total de los datos y la cantidad de datos. Una forma de hacerlo es mediante la función pretty() que utiliza un algoritmo para obtener números de clases que tengan límites redondo. Con el argumento n = 8 se le sugiere un número tentativo de clases. El algoritmo en función de la variabiliad de los datos puede sugerir más o menos intervalos. # Definir los intervalos lim &lt;- with(terneros, pretty(Peso, n = 8)) lim ## [1] 50 100 150 200 250 300 350 400 La diferencia o distancia entre dos \\(\\text{LI}\\) o \\(\\text{LS}\\) consecutivos se denomina amplitud de clase, \\(c = \\text{LI}_{i} - \\text{LI}_{i-1}\\) y la marca de clase es el valor central de la clase, i.e. promedio entre los límites o bien \\(\\text{MC}= \\text{LI}+ 0.5 c\\). En este caso la amplitud de las clases sugeridas por pretty() es de 50 kg. Las marcas de clases se obtienen sumando media amplitud a los límites inferiores. c &lt;- 50 mc &lt;- lim[1:7] + 0.5 * c mc ## [1] 75 125 175 225 275 325 375 con los límites definidos se debe categorizar o discretizar la variable contínua, es decir, transformar el vector Peso en un vector contenga el intervalo al que pertenece cada valor de peso observado. Esto se hace con la función cut() indicando los límites de clase en breaks. El argumento include.lowest = T es para aseguramos que todos los datos sean incluidos en las clases y right = F para que los intervalos no sean cerrados a derecha, es decir, que sean semi-abiertos a derecha. Con la función mutate() de dplyr creamos una nueva columna en el set de datos con las clases que contiene. # Dividir los datos en clases library(dplyr) terneros &lt;- mutate(terneros, clases = cut(Peso, breaks = lim, include.lowest = T, right = F)) terneros ## # A tibble: 1,598 x 5 ## IDV Procedencia Fecha Peso clases ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 NR047A202 La Rosita 2017-04-06 00:00:00 204 [200,250) ## 2 GN685B267 La Rosita 2017-04-06 00:00:00 186 [150,200) ## 3 AI101A751 La Rosita 2017-04-06 00:00:00 182 [150,200) ## 4 TM603C877 La Rosita 2017-04-06 00:00:00 186 [150,200) ## 5 TM420B797 La Rosita 2017-04-06 00:00:00 186 [150,200) ## 6 LH837F500 La Rosita 2017-04-06 00:00:00 208 [200,250) ## 7 NR047A217 La Rosita 2017-04-06 00:00:00 170 [150,200) ## 8 LH837F508 La Rosita 2017-04-06 00:00:00 188 [150,200) ## 9 GN685B256 La Rosita 2017-04-06 00:00:00 172 [150,200) ## 10 QW110A058 La Rosita 2017-04-06 00:00:00 172 [150,200) ## # ... with 1,588 more rows De este modo cada valor de peso queda asociado a una clase. Luego haciendo el conteo de clases se obtiene las frecuencias usando n # Obtener frecuencias simples absolutas tabla &lt;- count(terneros, clases) tabla ## # A tibble: 6 x 2 ## clases n ## &lt;fct&gt; &lt;int&gt; ## 1 [50,100) 4 ## 2 [100,150) 296 ## 3 [150,200) 812 ## 4 [200,250) 405 ## 5 [250,300) 80 ## 6 [350,400] 1 como no aparece la categoría [300, 350) hay que agregarla usando complete() del paquete tidyr. # Rellenar con clases faltantes library(tidyr) tabla &lt;- complete(tabla, clases, fill = list(n = 0)) tabla ## # A tibble: 7 x 2 ## clases n ## &lt;fct&gt; &lt;dbl&gt; ## 1 [50,100) 4 ## 2 [100,150) 296 ## 3 [150,200) 812 ## 4 [200,250) 405 ## 5 [250,300) 80 ## 6 [300,350) 0 ## 7 [350,400] 1 Esta tabla representa la distribución de los valores de cos de terneros. Se observa que la mayoría de los animales registró un peso de entre 150 y 200 kg ya que es el intervalo más frecuente. Existen algunos pocos terneros con cos llamativamente bajos y altos. La gran mayoría de los cos fueron entre 100 y 250 kg. Las frecuencias definidas hasta aquí se denominan frecuencias simples absolutas ya que representan el conteo de las cases. Cuando ese conteo se expresa en relación al total pasan a ser frecuencias simples relativas (\\(h_i = n_i/n\\)). Estas frecuencias pueden se pueden expresar de manera que muestren el número de veces que un valor o clase y los anteriores están representado en la muestra o población. Así se obtienen las frecuencias acumuladas absolutas (\\(F_i\\)) y relativas (\\(H_i = F_i/n\\)). Para agregar estas frecuencias y marcas de clase: # Agregar otras frecuencias tabla &lt;- mutate(tabla, mc = mc, F = cumsum(n), h = n/sum(n), H = F/sum(n)) tabla ## # A tibble: 7 x 6 ## clases n mc F h H ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 [50,100) 4 75 4 0.00250 0.00250 ## 2 [100,150) 296 125 300 0.185 0.188 ## 3 [150,200) 812 175 1112 0.508 0.696 ## 4 [200,250) 405 225 1517 0.253 0.949 ## 5 [250,300) 80 275 1597 0.0501 0.999 ## 6 [300,350) 0 325 1597 0 0.999 ## 7 [350,400] 1 375 1598 0.000626 1 Esta tabla nos permite conocer cerca del 50% de los datos estan contenidos en el rango [150, 200) kg. Los comandos anteriormente vistos se pueden encadenar con el operador %&gt;% para obtener de manera más compacta la tabla anterior: # Paquetes necesarios library(dplyr) library(tidyr) # Limites y marcas de clase lim &lt;- pretty(terneros$Peso, n = 8) c &lt;- 50 mc &lt;- lim[1:7] + 0.5 * c # Tabla de frecuencias tabla &lt;- terneros %&gt;% mutate(clases = cut(Peso, breaks = lim, include.lowest = T, right = F)) %&gt;% count(clases) %&gt;% complete(clases, fill = list(n = 0)) %&gt;% mutate(mc = mc, F = cumsum(n), h = n/sum(n), H = F/sum(n)) tabla ## # A tibble: 7 x 6 ## clases n mc F h H ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 [50,100) 4 75 4 0.00250 0.00250 ## 2 [100,150) 296 125 300 0.185 0.188 ## 3 [150,200) 812 175 1112 0.508 0.696 ## 4 [200,250) 405 225 1517 0.253 0.949 ## 5 [250,300) 80 275 1597 0.0501 0.999 ## 6 [300,350) 0 325 1597 0 0.999 ## 7 [350,400] 1 375 1598 0.000626 1 5.4.2 Gráficos La distribución de los datos también se puede representar de manera gráfica. Existen varias técnicas que se complementan. 5.4.2.1 Histograma El histograma es la representación gráfica de la tabla de frecuencias vista anteriormente. Consiste en graficar las frecuencias (simples, absolutas o relativas) mediante barras sobre un eje horizontal que representa la variable en estudio. La altura de las barras representa las frecuencias y el ancho la amplitud del intervalo de clase. En R mediante el paquete ggplot2 podemos graficar histogramas con distinta cantidad y amplitud de clases combinando los argumentos bins y binwidth. Por ejemplo, un histograma con 8 clases para los datos peso de terneros sería: library(ggplot2) p &lt;- ggplot(terneros) + aes(x = Peso) p + geom_histogram(bins = 8) Achicando el ancho de clases: p + geom_histogram(binwidth = 25) En el caso de variables discretas, las barras se grafican separadas y el gráfico se denomina gráfico de barras. Supongamos que queremos graficar las frecuencias de la variable Procedencia. 5.4.2.2 Gráfico de caja Es una técnica propuesta por John Tukey para representar la distribución de los datos mediante un gráfico exploratorio basado en medidas robustas (mediana, cuartiles, etc) que veremos más adelante. Permite ver la región central de los datos, el sesgo y la presencia datos atípicos leves y moderados En el caso de los terneros, la distribución de los pesos se puede representar con un gráfico de cajas usando geom_boxplot() # Boxplot peso terneros ggplot(terneros, aes(x = &quot;&quot;, y = Peso)) + geom_boxplot() + coord_flip() Según este gráfico el 50% de la distribución esta entre 158 y 206 y el sesgo es pequeño. Por defecto el gráfico de caja muestra los valores atípicos leves y extremos ya que toma 1.5 veces el rango intercuartilico. Para determinar si hay valores atípicos extremos se puede usar el argumento coef = 3. # Boxplot peso terneros con rango = 3 ggplot(terneros, aes(x = &quot;&quot;, y = Peso)) + geom_boxplot(coef = 3) + coord_flip() El valor peso = 384 es un outlier extremo. 5.4.3 Medidas de resumen Las medidas de resumen son funciones que permiten extraer información relevante de la distribución de los datos y expresarla de manera resumida mediante números. De acuerdo a la característica de la distribución que resumen se pueden clasificar en medidas de: tendencia central, dispersion, posición y forma Algo de notación Si \\(X\\) es un vector que representa una muestra con \\(n\\) observaciones, cada elemento de \\(X\\) se identifica por su orden mediante \\(X_i\\) donde \\(i\\) es la posición de la i-ésima observación. Ejemplo: si \\(X = [1.73, 1.84, 1.92, 2]\\) son las alturas de 4 plantas de maiz, la altura de la planta 3 es \\(X_i = 1.92\\) R representa los datos de manera parecida: x &lt;- c(1.73, 1.84, 1.92, 2) x[3] ## [1] 1.92 5.4.3.1 Medidas de tendencia central Resumen comportamiento de los datos más frecuentes, hacia donde se centra la distribución. Existen varias medidas las más comunes son la media, mediana y modo. La media aritmética, es el centro de gravedad de los datos. Se define como el cociente entre la suma de los valores de la muestra y la cantidad observaciones: \\[ \\bar{X} = \\dfrac{1}{n} \\sum_i^n x_i = \\dfrac{\\sum x_i}{n} = \\dfrac{x_1 + x_2 + \\cdots + x_n}{n} \\] Ejemplo: Los cos de 5 novillos son: 250, 230, 280, 235, 260. El peso promedio es: \\[ \\bar{X} = \\dfrac{250 + 230 + 280 + 235 + 260}{5} = 251 \\] Es la medida más común para representar la tendencia central de los datos y es fácil de calcular. Es un buen estimador de la media poblacional (\\(\\mu\\)). No obstante, es sensible a los valores extremos. En R la función que calcula la media se denomina mean() # peso promedio mean(terneros$Peso) ## [1] 182.6546 En promedio los terneros pesaron l82.65 kg. Por su parte la mediana es el valor que separa al conjunto de datos (ordenados) en dos partes iguales. Es una medida robusta ya que no es afectada por los valores extremos. \\[ \\tilde{X} = \\begin{cases} \\dfrac{x_{n/2} + x_{(n/2)+1}}{2} &amp;\\text{si n es par} \\\\ x_{(n+1)/2} &amp;\\text{si n es impar} \\end{cases} \\] Si \\(n\\) es par, \\(\\tilde{X}\\) es el promedio de los valores centrales (posiciones \\(n/2\\) y \\((n/2)+1\\)). Si \\(n\\) es impar, \\(\\tilde{X}\\) es el valor ubicado en la posicion \\((n+1)/2\\) En R la función que calcula la mediana se denomina median(): # peso mediano median(terneros$Peso) ## [1] 180 El 50% de los terneros pesó igual o menos de 180 kg. 5.4.3.2 Medidas de dispersión Son medidas que resumen el grado de variabilidad de los datos. Entre las más comunes se encuentran el rango, varianza y desviación estándar. El rango se define como la diferencia entre el valor máximo y mínimo de los datos. Es una medida muy simple pero altamente sensible a valores extremos ya que solamente usa la información del mínimo y máximo. \\[ \\text{rango} = \\text{max}(X) - \\text{min}(X) \\] En R el rango se obtiene de la misma manera mediante las funciones max() y min(). # Calculo del rango with(terneros, max(Peso) - min(Peso)) ## [1] 306 Una medida mejor para expresar la variabilidad es la varianza (\\(s^2\\)) que se define como el promedio de las desviacione cuadráticas de las observaciones respecto de la media. \\[ s^2 = \\dfrac{\\sum (x_i - \\bar{X})^2}{n-1} = \\dfrac{1}{n-1} \\left[ \\sum x_i^2 - \\dfrac{(\\sum x_i)^2}{n} \\right] \\] El denominador \\(n-1\\) representa los grados de libertad, es decir, el número de datos de la muestra que pueden variar cuando se usa el estimador de la media \\(\\bar{X}\\). Dado que los desvíos respecto del promedio tienen la propiedad de cancelarse \\(\\sum (x_i - \\bar{x}) = 0\\) los desvíos se deben elevar al cuadrado y esto a convierte una medida muy sensible a valores extremos. La desviación estándar (\\(s\\)) es la raiz cuadrada de la varianza \\[ s = \\sqrt{s^2} \\] La desviación estándar es interpretable ya que está en la escala original. Al igual que la varianza es sensible a valores extremos ya que utiliza \\(\\bar{X}\\) y los desvíos elevados al cuadrado. En R la varianza y desvio se obtienen con var() y sd(). # Varianza var(terneros$Peso) ## [1] 1383.534 # Desvío sd(terneros$Peso) ## [1] 37.19588 Si bien la desviación estándar es interpretable ya que está en la misma escala que la variable original, a veces es conveniente expresarle en relación al promedio de los datos para compararlo con otros datos o variables. El coeficiente de variación (\\(CV\\)) es una media de dispersión relativa para comparar la variabilidad entre muestras. \\[ CV = \\dfrac{s}{\\bar{X}} \\] En R podemos obtenerlo combinando las funciones sd() y mean() # CV de los cos with(terneros, sd(Peso)/mean(Peso)) ## [1] 0.2036406 Los pesos de los terneros varían un 20% en torno al promedio. 5.4.3.3 Medidas de posición Los cuantiles son una generalización del concepto de la mediana. En R se calculan con la función quantile(). Cuando los datos se dividen en cuatro partes iguales se llaman cuartiles \\((Q_i)\\), si se divide en 10 partes iguales son deciles (\\(D_i\\)) y para 100 partes iguales percentiles (\\(P_i\\)). \\[ \\tilde{X} = Q_2 = D_5 = P_{50} \\] Una medida importante es el rango intercuartílico (\\(IQR\\)) que indica entre que valores se encuentra el 50% central de la distribución de los datos \\[ IQR = Q_3 - Q_1 \\] Por ejemplo para obtener los valores de peso que separa a la muestra en 4 partes iguales: with(terneros, quantile(Peso, probs = c(0.25, 0.50, 0.75))) ## 25% 50% 75% ## 158 180 206 o bien, ¿cuánto pesa el ternero más liviano del 20% de los terneros más pesados? Eso sería el percentil 0.8. with(terneros, quantile(Peso, prob = 0.8)) ## 80% ## 213.2 Para obtener el percentil que corresponde a un dato particular de la muestra se usa la función empírica de distribución acumulada. # Obtener la ECDF ecdf_peso &lt;- ecdf(terneros$Peso) # Obtener el percentil del peso = 213.2 ecdf_peso(213.2) ## [1] 0.7997497 5.4.3.4 Medidas de forma Las medidas de forma resumen otros aspectos de la distribución como el sesgo o asimetría o la variabilidad en distribuciones unimodales o kurtosis. La asimetría de una distribución hace referencia a como se distribuyen los valores en torno a la media. En una distribución simétrica, la mitad izquierda es identica a la mitad derecha. La kurtosis indica cuanto se concentran los valores en torno a la media. Las distribuciones leptocurticas tienen menor variabilidad. Lo opuesto ocurre con las platicurticas. Hay varias formas de calcular los coeficientes de asimetría y kurtosis. Una de ellas deriva de los momentos estandarizados: \\[ m_k = \\dfrac{\\sum (X_i - \\bar{X})^k}{n} \\] Si \\(k = 1\\), \\(m = 0\\) dado que \\(\\sum (X_i - \\bar{X}) = 0\\). En cambio, si \\(k = 2\\), \\(m\\) es igual al estimador sesgado de la varianza poblacional. Así los momentos 3 y 4 tienen información sobre la asimetría y curtosis. El coeficiente \\(\\sqrt{b_1}\\) indica la asimetría: \\[ \\sqrt{b_1} = \\dfrac{m_3}{\\sqrt{m_2^3}} = \\dfrac{\\sqrt{n} \\sum (X_i - \\bar{X})^3}{\\sqrt{ \\left[ \\sum(X_i - \\bar{X})^2 \\right]^3}} \\] Si \\(\\sqrt{b_1} = 0\\) la distribución es simétrica Si \\(\\sqrt{b_1} &gt; 0\\) la distribución es sesgada a derecha Si \\(\\sqrt{b_1} &lt; 0\\) la distribución es sesgada a izquierda El coeficiente \\(b_2\\) indica la kurtosis \\[ b_2 = \\dfrac{m_4}{m_2^2} = \\dfrac{n \\sum (X_i - \\bar{X})^4}{\\left[ \\sum(X_i - \\bar{X})^2 \\right]^2} \\] Si \\(b_2 = 3\\) la distribución es normal Si \\(b_2 &gt; 3\\) la distribución es leptocirtoca Si \\(b_2 &lt; 3\\) la distribución es platocurtica En R los coeficientes de kurtosis y asimetría se obtienen del as funciones skewness() y kurtosis() del paquete moments: library(moments) # asimetría skewness(terneros$Peso) ## [1] 0.3905109 # kurtosis kurtosis(terneros$Peso) ## [1] 3.314532 5.4.3.5 Todas las medidas juntas Usando la función summarise() de dplyr se pueden calcular una o más estadísticas de resumen y resumirlas en forma de tabla. Asímismo también pueden calcularse por subconjuntos. library(moments) # General terneros %&gt;% summarise(n = length(Peso), media = mean(Peso), mediana = median(Peso), desv = sd(Peso), min = min(Peso), max = max(Peso), IQR = IQR(Peso), Q20 = quantile(Peso, 0.2), Q80 = quantile(Peso, 0.8), asim = skewness(Peso), kurt = kurtosis(Peso)) ## # A tibble: 1 x 11 ## n media mediana desv min max IQR Q20 Q80 asim kurt ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1598 183. 180 37.2 78 384 48 152 213. 0.391 3.31 # Estadítica de resumen por Procedencia terneros %&gt;% group_by(Procedencia) %&gt;% summarise(n = length(Peso), media = mean(Peso), mediana = median(Peso), desv = sd(Peso), min = min(Peso), max = max(Peso), IQR = IQR(Peso), Q20 = quantile(Peso, 0.2), Q80 = quantile(Peso, 0.8), asim = skewness(Peso), kurt = kurtosis(Peso)) ## # A tibble: 7 x 12 ## Procedencia n media mediana desv min max IQR Q20 Q80 ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Don Alberto 69 179. 182 26.9 110 222 46 155. 205. ## 2 La Alameda 201 190. 182 39.5 122 294 52 156 226 ## 3 La Estrella 118 179. 180 14.2 144 218 18 168 188 ## 4 La Rosita 98 180. 180 17.4 140 242 22 166 192 ## 5 La Segunda 43 229. 228 24.8 180 288 31 210 247. ## 6 Las Glicin… 494 160. 155 33.7 78 280 44 130 186 ## 7 Los Corral… 575 197. 196 35.8 96 384 50 168 226 ## # ... with 2 more variables: asim &lt;dbl&gt;, kurt &lt;dbl&gt; 5.5 Variabiles aleatorias y distribuciones de probabilidades Los resultados o eventos de un experimento aleatorio pueden ser cualitativos o cuantitativos (discretos o continuos) los cuales se asocian a variables aleatorias (VA) Variables porque sus valores no son todos iguales (hay variación) y aleatorias por que no se puede predecir con certeza que valor va a tomar, pero se puede asignar una probabilidad. Las VA pueden ser: Cualitativas cuando los posibles valores son categóricos, generalmente finitos y tipicamente pocas (a veces codificados como números). Ejemplo: el sexo de un insectos (variable) extraído al azar de una planta infestada (experimento) puede ser macho o hembra Cuantitativa discreta (VAD) cuando las observaciones pueden ser números enteros finitos o infinitos pero contables. Ejemplo el número de bichos blancos (variable) en una muestra de suelo obtenida al azar (experimento) puede ser 0, 1, 2, … Cuantitativa continua (VAC) cuando las observaciones pueden ser cualquier número del intervalo de números reales. Ejemplo la altura de una planta (variable) seleccionada al azar de un cultivo de soja (experimento) puede ser en cm 30, 45, 52.1, … 5.5.1 Distribución de probabilidades Una distribución de probabilidades hace referencia a la manera en que las probabilidades de los posibles valores de una variable aleatoria se distribuyen. Se pueden representar de manera gráfica, tabular o mediante una función. Ejemplo de VAD si se seleccionan dos vacas preñadas al azar de un rodeo grande, ¿cual es la probabilidad de que cualquiera de las dos para una ternera? La VA es el número de terneras que pare una vaca elegida al azar en dos pariciones consecutivas (X) Los posibles valores son 0 (MM), 1 (MH o HM) y 2 (HH) La probabilidad de que sea ternera en una parición dada es \\(p = P(\\text{ternera}) = 0.5\\) Sexo \\(X\\) \\(P(X = x)\\) MM 0 0.25 MH o HM 1 0.50 HH 2 0.25 La gráfico correspondiente a la tabla anterior sería: Lo anterior se puede representar mediante la funcion de probabilidad binomial: \\[ P(X = x) = f(x) = \\binom{2}{x} = p^x q^{2-x} \\] En el caso de una variable aleatoria continua (VAC), ésta puede tomar infinitos de valores posibles (puntos en un intervalo), asociados con mediciones en una escala continua. La probabilidad de un valor dado de \\(X\\) es 0 Ejemplo rendimientos de lotes de soja en qq/ha de una region amplia (población) La probabilidad de que el rendimiento de que un lote elegido al azar esté entre 34 y 38 es el área que ocupa el rectángulo (ancho de clase x frecuencia relativa) \\[ P(34 \\le X \\le 38) = 4 * 0.0601267 = 0.2405067 \\] Si dividimos en intervalos de 2 qq/ha… La probabilidad de que el rendimiento sea entre [35, 37] es el área que ocupa el rectángulo. La probabilidad es menor. \\[ P(35 \\le X \\le 37) = 2 * 0.001485 = 0.00297 \\] Si dividimos en intervalos sucesivamente pequeños (infinitamente pequeños) llegamos a la curva de densidad… La probabilidad de que sea igual a 34 es 0 ya que la curva representa la altura (densidad) pero el ancho de clase tiende a 0. En VAC la función de densidad de probabilidades \\(f(X)\\) describe la altura de la curva para un valor dado de \\(X\\). NO ES LA PROBABLIDAD!!. Es imposible asignar un valor de probabilidad a cada uno de los infinitos valores de \\(X\\) La probabilidad de que una VAC caiga en un intervalo, e.g. \\(x_0\\) y \\(x_1\\) se desprende de la interpretación probabilística del área de un intervalo en un histograma de frecuencias relativas y es igual al área bajo la curva de densidad \\[ P(x_0 \\le X \\le x_1) = \\int_{x_0}^{x_1} f(X) \\mathrm{d}X \\] La función de distribución de probabilidad acumulada \\(F(X)\\) es la probabilidad de que la VAC tome un valor igual a \\(x_0\\) o menor. \\[ P(X \\le x_0) = F(x_0) = \\int_{-\\infty}^{x_0} f(X) \\mathrm{d}X \\] 5.5.2 Esperanza y varianza La esperanza matemática \\(E(X)\\) de una VAC es el valor esperado de la variable aleatoria \\(X\\) en la población y se define como: \\[ E(X) = \\mu_X = \\int_{-\\infty}^{\\infty} X f(X) \\mathrm{d}X \\] La \\(E(X)\\) tiene la siguientes propiedades La esperanza de una constante es igual a la constante, \\(E(a) = a\\) La esperanza de la suma (o resta) de una constante y una variable aleatoria es la constante más (menos) la esperanza de la variable, \\(E(a \\pm X) = E(a) \\pm E(X) = a \\pm E(X)\\) La esperanza del producto de una constante y una variable aleatoria es el producto de la constante y la la esperanza de la variable, \\(E(aX) = E(a) E(X) = a E(X)\\) La esperanza de la suma (o resta) de dos variables aleatorias independientes es la suma (o resta) de sus esperanzas, \\(E(X \\pm Y ) = E(X) \\pm E(Y)\\) La varianza de una variable aleatoria \\(V(X)\\) es el valor esperado de los desvíos cuadráticos de los valores de una variable respecto a su esperanza (media). El desvio \\(D(X)\\) es la raiz cuadrada positiva. \\[ V(X) = E\\left\\{\\left[ x_i - E(X) \\right]^2\\right\\} = \\int_{-\\infty}^{\\infty} (x_i - \\mu_X)^2 f(X)\\mathrm{d}X \\\\ \\] Las propiedades de \\(V(X)\\) son: La varianza de una constante es igual 0, \\(V(a) = 0\\) La varianza de la suma (o resta) de una constante y una variable aleatoria es la varianza de la variable, \\(V(a \\pm X) = 0 + V(X) = V(X)\\) La varianza del producto de una constante y una variable aleatoria es el producto del cuadrado de la constante y la varianza de la variable, \\(V(aX) = a^2 V(X)\\) La varianza de la suma (o resta) de dos variables aleatorias independientes es la suma de sus varianza, \\(V(X \\pm Y ) = V(X) + V(Y)\\) 5.5.3 Distribución Normal Muchos procesos contínuos de la naturaleza se distribuyen siguiendo una curva con forma de campana, unimodal, simétrica: la distribución NORMAL \\[ X \\sim N(\\mu, \\sigma) \\] Las funciones de densidad y probabilidad acumulada para la Normal son: Función densidad \\[ f(X) = \\dfrac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\dfrac{(X - \\mu)^2}{2\\sigma^2}} \\] Función probabilidad acumulada \\[ F(X) = P(X \\le x_0) = \\dfrac{1}{\\sigma\\sqrt{2\\pi}} \\int_{-\\infty}^{x_0} e^{-\\dfrac{(X - \\mu)^2}{2\\sigma^2}} \\mathrm{d}X \\] Estas funciones están definidas en función de dos parámetros: Esperanza \\[ E(X) = \\int_{-\\infty}^{+\\infty} X f(X) \\mathrm{d}X = \\mu \\] Varianza \\[ V(X) = \\int_{-\\infty}^{+\\infty} \\left[X-E(X)\\right]^2 f(X) \\mathrm{d}X = \\sigma^2 \\] La esperanza o parámetro \\(\\mu\\) determina la posición de la curva. El parámetro \\(\\sigma\\) determina la forma. Valores característicos de la curva normal: \\(P(\\mu - \\sigma \\le X \\le \\mu + \\sigma) \\approx 0.6826\\) \\(P(\\mu - 2\\sigma \\le X \\le \\mu + 2\\sigma) \\approx 0.9544\\) \\(P(\\mu - 3\\sigma \\le X \\le \\mu + 3\\sigma) \\approx 0.9974\\) 5.5.4 Distribución de la media muestral La media aritmética (y cualquier estadístico muestral) que se calcula a partir de una muestra aleatoria de tamaño \\(n\\) es una variable aleatoria y por lo tanto tiene una distribución de probabilidades asociada En el caso de la media, su distribución muestral tiene \\(\\mu_{\\bar{X}} = \\mu\\) y \\(\\sigma_{\\bar{X}} = \\dfrac{\\sigma}{\\sqrt{n}}\\) 5.5.5 Teorema del Límite Central Si \\(\\bar{X}\\) es la media muestral calculada a partir de una muestra aleatoria de \\(n\\) observaciones de una población que tiene media \\(\\mu\\) y desvío \\(\\sigma\\), y \\(\\mu_\\bar{X}\\) y \\(\\sigma_\\bar{X}\\) la media y desviación estándar de la distribución de \\(\\bar{X}\\): La media de la distribución de muestreo es \\(\\mu_{\\bar{X}} = \\mu\\) La desviación estándar de la distribución de muestreo es \\(\\sigma_\\bar{X} = \\dfrac{\\sigma}{\\sqrt{n}}\\) Cuando \\(n\\) es grande (\\(n &gt; 30\\) *), la distribución de muestreo de \\(\\bar{X}\\) es aproximadamente Normal, siendo la aproximación más precisa a medida que aumenta \\(n\\) \\[ n \\rightarrow \\infty, \\bar{X} \\sim N(\\mu, \\sigma/\\sqrt{n}) \\] Cuando la población de \\(X\\) tiene distribución N, la distribución de muestreo de \\(\\bar{X}\\) es exactamente Normal para cualquier tamaño de muestra \\(n\\) El siguiente link es un simulador que permite visualizar el concepto de la distribución de la media muestral y el teorema del límite central. A partir de una población finita compuesta por los números 1 a 20 con distribución uniforme (misma probabilidad de elegir cada número), se simulan 500 muestras con reposición de tamaño 1 a 100. ¿Que succede con la distribución de las medias muestrales a medida que aumentamos el \\(n\\)? ¿Que pasa cuando \\(n = 1\\)? 5.6 Intervalos de Confianza: generalidades Un intervalo de confianza (IC) más informativo que un estimador puntual: incluye incertidumbre debida al error de estimación. De manera general un IC se construye mediante la siguiente expresión: \\[ P(\\hat{\\theta} - k\\sigma_{\\hat{\\theta}} \\leq \\theta \\leq \\hat{\\theta} + k\\sigma_{\\hat{\\theta}}) = 1 - \\alpha \\] donde: \\(\\theta\\) y \\(\\hat\\theta\\) son el parámetro a estimar y su estimador; \\(k\\) es un cuantil de la distribución de muestreo asociada a \\(\\hat\\theta\\); \\(\\sigma_{\\hat\\theta}\\) error del estimador; \\(1-\\alpha\\) coeficiente de confianza. De aquí se desprende que: Los límites son funciones del estimador puntual (VA) y su distribución de muestreo asociadas Una vez determinado el intervalo (fijados los límites), la probabilidad de que el \\(IC\\) contenga al parámetro a estimar es 1 ó 0, lo contiene o no lo contiene El Nivel de confianza \\((1-\\alpha)\\%\\) o coeficiente de confianza \\((1-\\alpha)\\) es la proporción de veces en muestreos repetidos que el \\(IC\\) obtenido por el procedimiento de estimación resultaría en un IC que contenga al parámetro poblacional Ejemplo Suponiendo que la media de la población de pesos de vacas de una región lechera es \\(\\mu = 550\\) kg, si tomáramos al azar 100 muestras de tamaño \\(n = 60\\) y estimáramos el intervalo de confianza para \\(\\bar{X}\\) con un \\((1-\\alpha) = 0.95\\) En este caso, al repetir el procedimiento de muestreo de 60 vacas unas 100 veces, solamente en 3/100 obtuvimos un IC que no contenía al parámetro poblacional que queríamos estimar. La amplitud del IC indica la calidad o confiabilidad de la inferencia y esta depende del nivel de confianza establecido, la variabilidad de la población original y el tamaño de la muestra. par(mfcol = c(1,3), mar = c(4, 0, 2, 0)) # Distinto alpha IC &lt;- data.frame(xbar = c(30, 30), sigma = c(9, 9), n = c(10, 10), y = c(0.75, .25)) IC &lt;- within(IC, { LI &lt;- xbar + qnorm(c(0.05, 0.005)) * sigma/sqrt(n) LS &lt;- xbar + qnorm(c(0.95, 0.995)) * sigma/sqrt(n) }) with(IC, { plot(xbar, y, ylim = c(0, 1), axes = F, ylab = &quot;&quot;, main = expression(paste(&quot;IC con (1-&quot;, alpha, &quot;)% = 90 y 99%&quot;))) axis(side = 1) arrows(LI, y, LS, y, length = 0.1, angle = 90, code = 3) }) # Distinto sigma IC &lt;- data.frame(xbar = c(30, 30), sigma = c(3, 9), n = c(10, 10), y = c(0.75, .25)) IC &lt;- within(IC, { LI &lt;- xbar + qnorm(0.025) * sigma/sqrt(n) LS &lt;- xbar + qnorm(0.975) * sigma/sqrt(n) }) with(IC, { plot(xbar, y, ylim = c(0, 1), axes = F, ylab = &quot;&quot;, main = expression(paste(&quot;IC con &quot;, sigma, &quot; = 3 y 9&quot;))) axis(side = 1) arrows(LI, y, LS, y, length = 0.1, angle = 90, code = 3) }) # Distinto n IC &lt;- data.frame(xbar = c(30, 30), sigma = c(9, 9), n = c(10, 100), y = c(0.75, .25)) IC &lt;- within(IC, { LI &lt;- xbar + qnorm(0.025) * sigma/sqrt(n) LS &lt;- xbar + qnorm(0.975) * sigma/sqrt(n) }) with(IC, { plot(xbar, y, ylim = c(0, 1), axes = F, ylab = &quot;&quot;, main = expression(paste(&quot;IC con n = 10 y 100&quot;))) axis(side = 1) arrows(LI, y, LS, y, length = 0.1, angle = 90, code = 3) }) Para \\(n\\) y \\(\\sigma\\) fijos, la amplitud aumenta con el nivel de confianza Para un \\((1-\\alpha)\\) y \\(n\\) fijos, la amplitud aumenta con la variabilidad de la población de origen Para un \\((1- \\alpha)\\) y \\(\\sigma\\) fijos, la amplitud aumenta para muestras más chicas 5.6.1 IC de la media (\\(\\mu\\)) con \\(\\sigma\\) desconocido Para muestras pequeñas de poblaciones normales o aproximadamente normales: se reemplaza \\(\\sigma\\) por su estimador insesgado \\(s\\) \\[ s = \\sqrt{\\dfrac{\\sum (X - \\bar{X})^2}{n-1}} \\] Estandarizando se obtiene el estadístico \\(t\\) tiene distribución \\(t\\) de Student. \\[ t = \\dfrac{\\bar{X} - \\mu}{\\dfrac{S}{\\sqrt{n}}} \\sim t_{n-1} \\] Los grados de libertad (\\(gl\\)) son los pedazos de información utilizadas en la estimación de \\(\\sigma\\) usando \\(S\\) En el cálculo de \\(s\\) se utilizan los desvíos respecto de \\(\\bar{X}\\), los cuales suman 0 siempre. Entonces, si se conocen las \\(n-1\\) desviaciones \\((X_i - \\bar{X})\\), la n-ésima desviación es fija para hacer \\(\\sum (X_i - \\bar{X}) = 0\\) \\(\\sigma\\) mide la dispersión en torno a \\(\\mu\\), entonces para estimar \\(\\sigma\\) hay que estimar primero \\(\\mu\\), luego quedan \\(n-1\\) piezas de información disponible para estimar \\(\\sigma\\) 5.6.1.1 Distribución \\(t\\) de Student Distribución de probabilidades para \\(\\bar{X}\\) obtenidas de tamaño pequeño \\(n&lt;30\\) de poblaciones normales Propiedades de la \\(t\\) de Student Hay infinitas distribuciones \\(t\\) se caracterizan por sus grados de libertad \\(\\nu =n-1\\) (tamaño de la muestra) Es simétrica y centrada en 0, igual que la \\(Z\\), \\(E(t) = 0\\) La varianza es \\(V(t) = \\nu / (\\nu -2)\\) y por lo tanto más variable que \\(Z\\) que tiene \\(V(Z) = 1\\) A medida que \\(\\nu\\) se incrementa, \\(t\\) se aproxima a \\(Z\\) Reemplazando \\(t\\) y despejando \\(\\mu\\) \\[ P \\left( \\bar{X} + t_{\\alpha/2, n-1} \\dfrac{S}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t_{1-\\alpha/2, n-1} \\dfrac{S}{\\sqrt{n}} \\right) = 1 - \\alpha \\] Veamos la estimación del IC de confianza de una media medainte un ejemplo: En un establecimiento avícola se toma una muestra al azar de 16 aves para determinar el aumento de peso. El aumento de peso promedio por semana fue de 96 g y con un desvío estándar de 9,5 g. Estimar el incremento de peso promedio para las aves de dicho establecimiento con un intervalo de confianza del 90%. # Datos n &lt;- 16 alfa &lt;- 0.10 xbar &lt;- 96 S &lt;- 9.5 # Cuantiles distribución t t_crit &lt;- qt(p = c(alfa/2, 1 - alfa/2), df = n-1) t_crit ## [1] -1.75305 1.75305 # Límites lim &lt;- xbar + t_crit * S/sqrt(n) lim ## [1] 91.83651 100.16349 Luego, el intervalo de confianza queda definido: \\[P(91.84 \\leq \\mu \\leq 100.16) = 0.90\\] Esto expresa la probabilidad de que en un muestreo futuro el valor de la medai poblacional esté comprendida entre estos límites. Cuando ya tenemos tomada la muestra, la interpretación es diferente: con un 90% de confianza, el intervalo de 91.84 a 100.16 g contiene al el aumento de peso por ave por semana en dicho establecimiento. 5.7 Test hipotesis: generalidades Las pruebas de hipótesis es uno de los métodos de inferencia estadística. A diferencia de la estimación de parámetros, en una prueba de hipótesis hay una idea previa del valor del un parámetro poblacional que será contrastado con los datos obtenidos de esa población. En una prueba de hipótesis se plantean dos modelos o hipótesis para explicar el fenómeno o proceso en estudio que produce los datos (población): \\[ H_0: \\theta = \\theta_0 \\quad \\text{vs} \\quad H_1: \\theta \\ne \\theta_0 \\] La hipótesis nula \\(H_0\\) es la que se usa para construir el modelo de la población con la idea de verificar su falsedad. Refleja un pensamiento escéptico. La hipótesis alternativa o de investigación \\(H_1\\) es la alternativa a considerar en caso de rechazar \\(H_0\\). La evidencia empírica que sustenta o rechaza el modelo nulo \\(H_0\\) se obtiene de una muestra aleatoria de la población sobre la cual se quiere inferir. Una prueba de hipótesis estadística se basa en el concepto de prueba por contradicción, es decir que se evalúa la \\(H_1\\) probando o no la falsedad de \\(H_0\\). Esto involucra: Formular las hipótesis \\(H_1\\) y \\(H_0\\) Cálcular el estadístico de prueba apropiado, e.g. \\(Z_{\\theta_0}\\) Determinar la zona de rechazo y regla de decisión. Chequear de supuestos Concluir 5.7.1 ¿Cómo se formulan las hipótesis? Las hipótesis pueden formularse teniendo los siguientes criterios generales: La afirmación de que \\(\\theta\\) es igual a un determinado valor siempre tiene que estar incluida en \\(H_0\\). El valor hipotético de \\(\\theta\\) en \\(H_0\\) es el valor nulo \\(\\theta_0\\) La afirmación sobre \\(\\theta\\) que se quiere soportar or detectar con los datos es la \\(H_1\\) La negación de \\(H_1\\) es la \\(H_0\\) La \\(H_0\\) se presume correcta a menos que hay evidencia suficiente para rechazarla en pos de la \\(H_1\\) Ejemplos 1 Un edafólogo quiere evaluar si el contenido de N total de los suelos de una región es igual o inferior a 0.12%. Como su hipótesis de trabajo contiene la igualdad, entonces \\(H_0: \\mu \\le 0.12\\% \\quad \\text{vs} \\quad H_1: \\mu &gt; 0.12\\%\\) Ejemplos 2 Otro edafólogo quiere evaluar si el contenido de N total es menor a 0.12%. En este caso, la hipótesis de trabajo no incluye la igualdad, entonces: \\(H_0: \\mu \\ge 0.12\\% \\quad \\text{vs} \\quad H_1: \\mu &lt; 0.12\\%\\). Ejemplo 3 A un tercero le interesa saber si el nivel de N total es distinto de 0.12%. Como la hipotesis de trabajo plantea la desigualdad, entonces, \\(H_0: \\mu = 0.12\\% \\quad \\text{vs} \\quad H_1: \\mu \\ne 0.12\\%\\) 5.7.2 Estadístico de prueba El estadísico de prueba es un valor estandarizado que se calcula a partir de los datos de la muestra aplicando una función. Como la muestra es un conjunto de variables aleatorias, el resultado de la función aplicada es a su vez una variable aleatoria cuyos posibles valores tienen una distribución de probabilidades asociada la cual está determinada por la \\(H_0\\) y los supuestos 5.7.3 Zona de rechazo La zona de rechazo está compueta por los valores de la distribución del estadístico de prueba \\(Z_\\theta\\) que soportan la \\(H_1\\) y contradicen \\(H_0\\), es decir, los valores de \\(\\theta\\) con que permiten rechazar \\(H_0\\). La \\(H_1\\) determina donde está la zona de rechazo y el sentido de la interpretación de la evidencia. De este modo las pruebas pueden ser bilaterales si \\(H_1: \\theta \\ne \\theta_0\\) o unilaterales izquierda \\(H_1: \\theta &lt; \\theta_0\\) o derecha \\(H_1: \\theta &gt; \\theta_0\\) 5.7.4 Errores En toda prueba de hipótesis se pueden cometer errores al tomar la decisión. El tipo de error dependerá de la decisión tomada y el valor verdadero de la \\(H_0\\). Decisión \\(H_0\\) es cierta \\(H_0\\) es falsa se rechaza \\(H_0\\) Error Tipo I No hay error no se rechaza \\(H_0\\) No hay error Error Tipo II Si bien no podemos conocer el verdadero valor del los parámetros poblacionales, y por lo tanto desconocemos si la \\(H_0\\) es verdadera o falsa, es posible estimar las probabilidades de cometer los errores Tipo I y tipo II, las que se denominan \\(\\alpha\\) y \\(\\beta\\) respectivamente. Supongamos que tenemos dos hipótesis en juego \\(H_0: \\mu = 1\\) vs \\(H_1: \\mu = 1\\). El siguiente gráfico muestra las áreas sombreadas \\(\\alpha\\) y \\(\\beta\\) que representan la probabilidad de cometer error tipo I y II si tomáramos la información del estadísico \\(z_0\\) para decidir sobre \\(H_0\\). Si el modelo válido fuera el especificado en \\(H_0\\), el área \\(\\alpha\\) indica la probabilidad de rechazar \\(H_0\\) cuando es verdadera, es decir, obtener estadísticos igual o más extremos que \\(z_0\\) bajo el supuesto de \\(H_0\\). En cambio, si \\(H_1\\) fuese verdadera, el área \\(\\beta\\) representa la probabilidad de no rechazar \\(H_0\\) cuando esta es falsa. Figure 5.2: Distribución de probabilidades de estadístico de prueba bajo supuesto de H0 y H1 \\[ P(\\text{rechazar $H_0$ | $H_0$ es cierta}) = \\alpha \\\\ P(\\text{no rechazar $H_0$ | $H_0$ es falsa}) = \\beta \\] \\(\\alpha\\) y \\(\\beta\\) dependen de la verdadera distancia entre las medias, la variabilidad de la población en estudio y el tamaño de la muestra. No se pueden controlar ambas tasas de error a la vez. Así como \\(\\beta\\) determina las probabilidades de cometer error tipo II, el complemento \\(1-\\beta\\) representa la probabilidad que tenemos de decidir correctamente sobre \\(H_0\\) rechazándola cuando realmente es falsa. Esto se denomina potencia \\[ P(\\text{rechazar $H_0$ | $H_0$ es falsa}) = 1 - \\beta \\] Para un nivel de significancia \\(\\alpha\\) dado, la potencia se halla utilizando la distribución que asume \\(H_1\\) como verdadera. 5.7.5 Regla de decisón y valores \\(p\\) Para decidir sobre una hipótesis se debe tener una regla de decisión fijando un \\(\\alpha\\) (probabilidad de error Tipo I) Opción 1 A partir del \\(\\alpha\\) calculamos el valores crítico o de tabla para el estadístico de prueba \\(Z_\\theta\\) y deliminatamos las zonas de rechazo o aceptación que contienen todos los valores de \\(Z_\\theta\\) que rechazasn \\(H_0\\). Para bilaterales: Si \\(|Z_\\theta| \\ge z_{1-\\alpha/2}\\) se rechza \\(H_0\\) Si \\(|Z_\\theta| &lt; z_{1-\\alpha/2}\\) no se rechza \\(H_0\\) Para unilaterales izquierda Si \\(Z_\\theta \\ge z_{\\alpha}\\) no se rechza \\(H_0\\) Si \\(Z_\\theta &lt; z_{\\alpha}\\) se rechza \\(H_0\\) Para unilaterales derecha Si \\(Z_\\theta \\le z_{1-\\alpha}\\) no se rechza \\(H_0\\) Si \\(Z_\\theta &gt; z_{1-\\alpha}\\) se rechza \\(H_0\\) Opción 2 Asumiendo \\(H_0\\) y una distribución del estadístico (e.g. Normal), se calcula la probabilidad \\(p\\) de ocurrencia de un valor igual o más extremo (a una o dos colas). \\[ P(Z \\ge Z_{\\theta_0} | H_0) = p \\] Luego: Si \\(p &gt; \\alpha\\), no hay evidencias para rechazar \\(H_0\\), aunque no se prueba que ésta sea verdadera Si \\(p \\le \\alpha\\), hay evidencia para rechazar \\(H_0\\), aunque no se esta probando que \\(H_0\\) sea falsa o \\(H_1\\) sea verdadera ¿Qué es el valor p? Es la probabilidad de que, si se repite el muestreo, el estadístico de prueba a obtener sea igual o más extremo que el observado en los datos asumiendo que \\(H_0\\) es cierta. Si los datos no concuerdan con el modelo nulo, entonces hay evidencia para descartarlo en favor del alternativo 5.7.6 Conclusiones La conclusión consta de 3 partes fundamentales: ¿Cuál es la decisión? ¿Que sucede con \\(H_0\\)? ¿Por qué se llega a esa decisión? El estadístico con valor p o bien con el valor crítico y nivel de significancia. Interpretación o consencuencias en el contexto del problema o pregunta de investigación Una inferencia completa es cuando además de contestar sobre 1 y 2 se agrega información sobre las consecuencias de haber recvhazado \\(H_0\\) en el contexto del problema de investigación. Agregar información sobre la magnitud y sentido de las diferencias agregar más información a la inferencia. 5.8 Comparación de dos poblaciones En experimentos comparativos el interés es determinar si las respuestas de las unidades experimentales provienen de una distribución común con una única \\(\\mu\\) o bien hay evidencia para considerar que cada tratamiento o grupo tiene su propia distribución. En otras palabras: ¿las muestras con \\(\\bar{y}_1\\) y \\(\\bar{y}_2\\) provienen de dos poblaciones distintas con \\(\\mu_1\\) y \\(\\mu_2\\), o de una sola población con \\(\\mu\\)? \\[ E(\\bar{y}_1) = \\mu_1 \\\\ E(\\bar{y}_2) = \\mu_2 \\] \\[ E(\\bar{y}_1) = \\mu \\\\ E(\\bar{y}_2) = \\mu \\] 5.8.1 Muestras independientes 5.8.1.1 Modelo lineal aditivo A los fines del análisis estadístico es útil desarrollar un modelo estadístico que permita representar cada observación de las muestras. En un experimento simple con dos grupos o tratamientos podemos pensar en el siguiente modelo: \\[ y_{ij} = \\mu_i + e_{ij} \\quad \\quad i = 1, 2; j = 1, \\dots, n_i \\] donde: \\(y_{ij}\\) es la j-ésima observación del i-ésimo tratamiento; \\(\\mu_i\\) es la media del i-ésimo tratamiento; \\(e_{ij}\\) es el error aleatorio asociado a la j-ésima observación del i-ésimo tratamiento. Este modelo se denomina codelo de medias de celda porque cada observacion es representada por la media de su tratamiento mas un componente aleatorio. Los supuestos de este moelo se resumen en: \\(e_{iid} \\sim N(0, \\sigma^2)\\), es decir los errores o residuos \\(e\\) son variables aleatorias independientes e idénticamente distribuídas con distribución normal con media 0 y varianza constante. La independencia significa que cada individuo no contiene información de la respuesta de otra observación: i.e. \\(Cor(e_{ij}, e_{i&#39;j&#39;}) = 0\\). Por otro lado, la distribución Normal con media 0 y varianza constante indica que cada las respuestas de los individuos se centran en torno a la media de su grupo y la varianza de cada grupo es similar (homocedasticidad, \\(\\sigma^2\\) no tiene subíndice). Una forma alternativa de representar los datos es mediante el modelo de efectos donde en vez de representar a cada observacion por su media mas un error, el componente fijo se separa en una media general y un efecto o distancia entre ese tratamiento y la media general. \\[ y_{ij} = \\mu + \\tau_i + e_{ij} \\quad \\quad i = 1, 2; j = 1, \\dots, n_i \\] donde: \\(y_{ij}\\) es la j-ésima observación del i-ésimo tratamiento; \\(\\mu\\) es la media general; \\(\\tau_i\\) es la desviación o efecto del i-ésimo tratamiento respecto de \\(\\mu\\), es decir \\(\\tau_i = \\mu_i - \\mu\\); \\(e_{ij}\\) es el error aleatorio asociado a la j-ésima observación del i-ésimo tratamiento. Este modelo es equivalente al anterior y tiene los mismos supuestos. Así, a partir de estos modelos podemos plantear dos hipótesis que representen las dos situaciones: las muestras con \\(\\bar{y}_1\\) y \\(\\bar{y}_2\\) provienen de una sola población con \\(\\mu\\) o bien de dos poblaciones distintas con \\(\\mu_1\\) y \\(\\mu_2\\) \\[ H_0: \\mu_1 - \\mu_2 = 0 \\quad \\text{o bien} \\quad H_0: \\tau_i = 0\\\\ H_1: \\mu_1 - \\mu_2 \\ne 0 \\quad \\text{o bien} \\quad H_1:\\tau_i \\ne 0 \\\\ \\] Para testear estas hipótesis podemos construir un estadístico de prueba a partir de las diferencias observadas y una idea de la variabilidad de la distribución de la diferencia de medias muestrales. \\[ t = \\dfrac{(\\bar{y}_1 - \\bar{y}_2) - (\\mu_1 - \\mu_2)}{s_{\\bar{y}_1 - \\bar{y}_2}} \\sim t_{\\nu} \\] donde \\(s_{\\bar{y}_1 - \\bar{y}_2}\\) es un estimador muestral del \\(\\sigma_{\\mu_1 - \\mu_2}\\). Dado que no conocemos las varianzas de esas poblaciones, para estimar la dispersión de las diferencias de medias meustrales usamos las varianzas muestrales. Su forma de cálculo depende de si las dos poblaciones tienen varianza común \\(\\sigma^2_1 = \\sigma^2_2 = \\sigma^2\\) Finalmente, la regla de decisión es: Si \\(| t | &gt; t_{\\nu, 1-\\alpha/2}\\), entonces se rechaza \\(H_0\\) Si \\(| t | \\le t_{\\nu, 1-\\alpha/2}\\), entonces se no rechaza \\(H_0\\) 5.8.1.2 Varianzas homogéneas (\\(\\sigma^2_1 = \\sigma^2_2\\)) Si asumimos que \\(\\sigma^2_1 = \\sigma^2_2\\), entonces \\(\\sigma^2_{\\bar{y}_1 - \\bar{y}_2}\\) se estima usando la información de \\(s^2_1\\) y \\(s^2_2\\) en una varianza amalgamada \\[ s^2_a = \\dfrac{(n_1-1) s^2_1 + (n_2-1) s^2_2}{n_1 + n_2 - 2} \\] y el estadístico es \\(t\\) sigue una distribución \\(t\\) con \\(n_1 + n_2 - 2\\) grados de libertad \\[ t = \\dfrac{(\\bar{y}_1 - \\bar{y}_2) - (\\mu_1 - \\mu_2)}{S_a \\sqrt{\\dfrac{1}{n_1} + \\dfrac{1}{n_2}}} \\sim t_{n_1 + n_2 - 2} \\] Ahora veremos como se procede en R para comparar dos medias de muestras independientes mediante el siguiente ejemplo: Un mejorador de trigo desea comparar dos materiales experimentales (Exp1 y Exp2) para determinar si sus rendimientos difieren significativamente fijando una probabilidad de cometer error tipo I de 5% (\\(\\alpha\\) = 0.05). Para ello, en un sector del campo experimental, delimita 20 parcelas de 2 x 4 m y siembra al azar en cada parcela una de las dos variedades. Luego, a cosecha, determina el rendimiento de cada parcela cortando espigas de 3 m2. Los rendimientos en qq ha-1 fueron: ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select Exp 1 ## 46.77, 38.29, 48.14, 23.32, 37.08, 48.19, 35.12, 32.94, 34.52, 43.25 Exp 2 ## 34.88, 34.02, 38.05, 33.32, 32.73, 37.3, 33.68, 31.83, 32.42, 35.11 Lo primero que necesitamos es descargar el archivo trigo.xlsx a la carpeta data del proyecto y luego importarlo en R con el paquete readxl. library(readxl) trigo &lt;- read_excel(&quot;./data/trigo.xlsx&quot;) Una vez cargados los datos en la tabla trigo, una buena práctica sería explorarlos mediante gráficos y medidas de resumen. Esto nos permite apreciar algunas características de la distribución de los datos así como detectar errores o datos atípicos. # Cargar dplyr library(dplyr) # Medias de resumen res &lt;- trigo %&gt;% group_by(Variedad) %&gt;% summarise(ybar = mean(rend), s = sd(rend), n = n()) res ## # A tibble: 2 x 4 ## Variedad ybar s n ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Exp1 38.8 7.94 10 ## 2 Exp2 34.3 2.04 10 # cargar paquetes ggplot2 y ggthemes y definir tema library(ggplot2) library(ggthemes) theme_set(theme_bw()) # Gráfico de caja ggplot(trigo, aes(x = Variedad, y = rend)) + geom_boxplot() ¿Existen diferencias significativas entre ambas variedades? Las hipótesis en juego son: \\[ H_0: \\mu_1 - \\mu_2 = 0 \\quad \\text{vs} \\quad H_1: \\mu_1 - \\mu_2 \\ne 0 \\] Si asumimos muestras independientes y varianzas homogéneas, bajo \\(H_0\\) la varianza de los rendimientos sería: \\[ \\begin{align} s^2_a &amp;= \\dfrac{(n_1-1) s^2_1 + (n_2 - 1) s_2^2}{n_1+n_2-2} = \\\\ &amp;= \\dfrac{(9) 63.09 + (9) 4.17}{18} = 33.63 \\end{align} \\] Luego el estadístico de prueba es: \\[ \\begin{align} t &amp;= \\dfrac{(\\bar{y}_1 - \\bar{y}_2) - (\\mu_1 - \\mu_2)}{s_a \\sqrt{\\dfrac{1}{n_1} + \\dfrac{1}{n_2}}} = \\\\ &amp;= \\dfrac{38.76 - 34.33}{5.8} = 1.71 \\end{align} \\] Como \\(|t = 1.71| \\le t_{1-0.05/2, 18} = 2.100922\\), entonces no se rechaza \\(H_0\\). En R usando la función t.test()… # Prueba t t.test(rend ~ Variedad, trigo, paired = F, var.equal = T, alternative = &#39;two.sided&#39;) ## ## Two Sample t-test ## ## data: rend by Variedad ## t = 1.7074, df = 18, p-value = 0.1049 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.020611 9.876611 ## sample estimates: ## mean in group Exp1 mean in group Exp2 ## 38.762 34.334 Conclusión: la muestra no proporciona evidencia suficiente para rechazar \\(H_0\\) al 5% de significancia, por lo tanto las diferencias de rendimiento entre Exp1 y Exp2 no son estadísticamente significativas (p = 0.1049). Con un 95% de confianza, se estima que la verdadera diferencia de rendimiento entre Exp1 y Exp2 está contenida en el intervalo -1.02 y 9.88 qq ha-1 5.8.1.3 Varianzas heterogéneas (\\(\\sigma^2_1 \\ne \\sigma^2_2\\)) Si en vez de asumir la homogeneidad de varianzas quisiéramos verificarla mediante una prueba de hipótesis, podríamos plantear lo siguiente: \\[ H_0: \\sigma^2_1 = \\sigma^2_2 \\\\ H_1: \\sigma^2_1 \\ne \\sigma^2_2 \\] Esto lo podemos chequear con la prueba \\(F\\) \\[ F = \\dfrac{s^2_1}{s^2_2} \\sim F_{n_1-1; n_2-1} \\] donde por conveniencia \\(s^2_1 &gt; s^2_2\\). En este caso, la regla de regla decisión sería: Si \\(F &gt; F_{n_1-1; n_2-1; 1-\\alpha/2}\\), entonces se rechaza \\(H_0\\) Si \\(F \\le F_{n_1-1; n_2-1; 1-\\alpha/2}\\), entonces no se rechaza \\(H_0\\) Si tenemos evidencia para rechazar la homogeneidad de varianzas, tenemos que considerar que \\(\\sigma^2_1 \\ne \\sigma^2_2\\) y \\(\\sigma^2_{\\bar{y}_1 - \\bar{y}_2}\\) se estima usando las varianzas muestrales sin combinar y el estadístico \\(t\\) que tiene distribución \\(t\\) con \\(\\delta\\) grados de libertad \\[ t = \\dfrac{(\\bar{y}_1 - \\bar{y}_2) - (\\mu_1 - \\mu_2)}{\\sqrt{\\dfrac{s^2_1}{n_1} + \\dfrac{s^2_2}{n_2}}} \\sim t_\\delta \\] Los grados de libertad se aproximan por Welch-Satterwaite: \\[ \\delta = \\dfrac{\\left(\\dfrac{s^2_1}{n_1-1} + \\dfrac{s^2_2}{n_2} \\right)^2} {\\dfrac{1}{n_1-1} \\left(\\dfrac{s^2_1}{n_1} \\right)^2 + \\dfrac{1}{n_2-1} \\left(\\dfrac{s^2_2}{n_2} \\right)^2} \\] En R tenemos la función var.test() para testear dos varianzas: # Prueba igualdad varianza de dos poblaciones var.test(rend ~ Variedad, trigo) ## ## F test to compare two variances ## ## data: rend by Variedad ## F = 15.113, num df = 9, denom df = 9, p-value = 0.000408 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 3.753976 60.846812 ## sample estimates: ## ratio of variances ## 15.11349 En función de este resultado hay evidencia suficiente para rechazar \\(H_0\\) (p = 0.000408), por lo tanto no se puede asumir que las varianzas son homogéneas, hay que usar la aproximación de correción Welch-Satterwaite. Para eso tenemos que indicar el argumento var.equal = F en la llamada de t.test # Prueba t para varianzas heterogéneas t.test(rend ~ Variedad, trigo, var.equal = F) ## ## Welch Two Sample t-test ## ## data: rend by Variedad ## t = 1.7074, df = 10.186, p-value = 0.118 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.336284 10.192284 ## sample estimates: ## mean in group Exp1 mean in group Exp2 ## 38.762 34.334 La conclusión final no cambia, las diferencias entre variedades no son estadísticamente significativas al 5% (p = 0.118). 5.8.2 Muestras apareadas En ocaciones Se puede disminuir la varianza de los errores \\(\\sigma^2_{e}\\) asignando los tratamientos a pares de unidades experimentales homogéneas (e.g. parcelas próximas, animales mismo peso, edad, sexo, tiempos, etc.) Par \\(y_1\\) \\(y_2\\) \\(y_D = y_1 - y_2\\) 1 \\(y_{11}\\) \\(y_{21}\\) \\(y_1\\) 2 \\(y_{12}\\) \\(y_{22}\\) \\(y_2\\) \\(\\dots\\) \\(\\dots\\) \\(\\dots\\) \\(\\dots\\) n \\(y_{1n}\\) \\(y_{2n}\\) \\(y_n\\) Luego, la respuesta se mide sobre la diferencia entre pares de observaciones \\[ \\bar{y}_D = \\dfrac{1}{n_D} \\sum (y_{1j} - y_{2j}) \\sim N \\left(\\mu_D, \\dfrac{\\sigma_D}{\\sqrt{n_D}} \\right) \\] 5.8.2.1 Modelo lineal aditivo En esta caso, además del efecto debido a los grupos o tratamientos se debe agregar un término que represente el efecto de los pares \\(\\rho\\). \\[ y_{ij} = \\mu + \\tau_i + \\rho_j + e_{ij} \\quad \\quad i = 1, 2; j = 1, \\dots, n_i \\] donde: \\(y_{ij}\\) es la j-ésima observación del i-ésimo par; \\(\\mu\\) es la media general; \\(\\tau_i\\) es la desviación o efecto del i-ésimo tratamiento o grupo respecto de \\(\\mu\\), es decir \\(\\tau_i = \\mu_i - \\mu\\); \\(\\rho_j\\) es la desviación o efecto del j-ésimo par; \\(e_{ij}\\) es el error aleatorio asociado a la j-ésima observación del i-ésimo tratamiento. Los supuesos son iguales a los casos anteriores con el agregado de la aditividad de los pares y tratamientos, es decir \\((\\tau\\rho)_{ij} = 0\\). En este caso, al trabajar sobre las diferencias, la prueba de hipótesis pasa a ser univariada o de una muestra: \\[ H_0: \\mu_D = 0 \\\\ H_1: \\mu_D \\ne 0 \\\\ \\] Con el estadístico de prueba: \\[ t = \\dfrac{\\bar{y}_D - \\mu_D}{S_{\\bar{y}_D}} \\sim t_{n_D - 1} \\] donde \\(S_{\\bar{y}_D}\\) es un estimador muestral del desvió de la diferencia de a pares \\(\\sigma_{\\mu_D}\\). De este modo la regla de decisión sería: Si \\(| t | &gt; t_{1-\\alpha/2,n_D -1}\\), entonces se rechaza \\(H_0\\) Si \\(| t | \\le t_{1-\\alpha/2, n_D -1}\\), entonces no se rechaza \\(H_0\\) Volviendo al ejemplo de los datos de trigo, suponiendo que el experimentador advertido por las diferencias de suelo, agrupó las parcelas en pares según la similitud de lo suelos. # Gráfico de pares ggplot(trigo, aes(x = Variedad, y = rend, color = factor(Parcela))) + geom_point() + geom_line(aes(group = Parcela)) Cada línea conecta los rendimientos de pareclas vecinas. Hay pares donde la diferencia es positiva o negativa. Esto supone que las respuestas entre parcelas próximas estarían correlacionada positivamente. Para el calculo de la correlación la tabla debería contener una columna para al respuesta de cada material y cada fila debería ser una observación o par. # paquete para manipular datos library(tidyr) # Convertir tabla para calculo correlación trigo2 &lt;- trigo %&gt;% dplyr::select(Parcela, Variedad, rend) %&gt;% spread(., key = Variedad, value = rend) # Coeficiente de correlacion lineal dplyr::select(trigo2, Exp1, Exp2) %&gt;% cor() ## Exp1 Exp2 ## Exp1 1.0000000 0.7822982 ## Exp2 0.7822982 1.0000000 La correlación entre los rendimientos es 0.78. Es decir que las diferencias entre parcelas del mismo par son menores a las diferencias entre parcelas de pares diferentes. En el gráfico de dispersión se puede ver la relación entre los pares de rendimientos # Gráfico dispersión ggplot(trigo2, aes(x = Exp1, y = Exp2)) + geom_point() + geom_smooth(method = &#39;lm&#39;, se = F) Dado que las observaciones están pareadas por la parcela la variable de interés es la diferencia de rendimientos dentro de cada par. # Diferencias de a pares trigo2 &lt;- mutate(trigo2, dif = Exp1 - Exp2) ggplot(trigo2, aes(x = &quot;&quot;, y = dif)) + geom_boxplot() + coord_flip() ¿Hay diferencias entre tratamientos? ¿En que sentido? La prueba de hipótesis para muestras pareadas en R se indica con el argumento paired = T de t.test(). t.test(rend ~ Variedad, trigo, paired = T) ## ## Paired t-test ## ## data: rend by Variedad ## t = 2.164, df = 9, p-value = 0.05868 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.2008694 9.0568694 ## sample estimates: ## mean of the differences ## 4.428 Conclusión: la muestra no proporciona evidencia suficiente para rechazar \\(H_0\\), por lo tanto las diferencias de rendimiento entre Exp1 y Exp2 no son estadísticamente significativas al 5% (p = 0.05868). Con un 95% de confianza, se estima que la verdadera diferencia de rendimiento entre Exp1 y Exp2 está contenida en el intervalo -0.20 y 9.06 qq ha-1. "]
]
